{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0299367-2cb8-4dbe-a377-41186fcb5307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ktang2/.conda/envs/NN/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0376b0be-92a3-433a-9efb-a4fb7d555cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = '.'\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0551184-11fc-4156-865c-f5edca3fa614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(src_dir, genres, song_samples, spec_format, debug = True):\n",
    "    # Empty array of dicts with the processed features from all files\n",
    "    arr_specs = []\n",
    "    arr_genres = []\n",
    "\n",
    "    # Read files from the folders\n",
    "    for x,_ in genres.items():\n",
    "        folder = src_dir + x\n",
    "\n",
    "        for root, subdirs, files in tqdm(os.walk(folder)):\n",
    "            for file in files:\n",
    "                # Read the audio file\n",
    "                file_name = folder + \"/\" + file\n",
    "                signal, sr = librosa.load(file_name)\n",
    "                signal = signal[:song_samples]\n",
    "\n",
    "                # Debug process\n",
    "                if debug:\n",
    "                    print(\"Reading file: {}\".format(file_name))\n",
    "\n",
    "                # Convert to dataset of spectograms/melspectograms\n",
    "                signals, y = splitsongs(signal, genres[x])\n",
    "                # Convert to \"spec\" representation\n",
    "                specs = spec_format(signals)\n",
    "\n",
    "                # Save files\n",
    "                arr_genres.extend(y)\n",
    "                arr_specs.extend(specs)\n",
    "\n",
    "    return np.array(arr_specs), np.array(arr_genres)\n",
    "\n",
    "def to_melspectrogram(songs, n_fft = 1024, hop_length = 512):\n",
    "    '''\n",
    "    Method to convert a list of songs to a np array of melspectrograms\n",
    "    '''\n",
    "    # Transformation function\n",
    "    melspec = lambda x: librosa.feature.melspectrogram(y = x, n_fft = n_fft,\n",
    "        hop_length = hop_length)[:,:,np.newaxis]\n",
    "\n",
    "    # map transformation of input songs to melspectrogram using log-scale\n",
    "    tsongs = map(melspec, songs)\n",
    "    return np.array(list(tsongs))\n",
    "\n",
    "def splitsongs(X, y, window = 0.1, overlap = 0.5):\n",
    "    '''\n",
    "    Method to split a song into multiple songs using overlapping windows\n",
    "    '''\n",
    "    # Empty lists to hold our results\n",
    "    temp_X = []\n",
    "    temp_y = []\n",
    "\n",
    "    # Get the input song array size\n",
    "    xshape = X.shape[0]\n",
    "    chunk = int(xshape*window)\n",
    "    offset = int(chunk*(1.-overlap))\n",
    "\n",
    "    # Split the song and create new ones on windows\n",
    "    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n",
    "    for s in spsong:\n",
    "        temp_X.append(s)\n",
    "        temp_y.append(y)\n",
    "\n",
    "    return np.array(temp_X), np.array(temp_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d384e8-64df-4cb6-8cf4-dc3dc41e9d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gtzan_dir = root_dir + '/genres/'\n",
    "song_samples = 660000\n",
    "genres = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4,\n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13026a30-249b-43fe-95ab-02b307ee5e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in the data..\n",
      "Using saved training data..\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading in the data..\")\n",
    "if os.path.isfile(os.path.join(root_dir, \"x_gtzan_npy.npy\")) and os.path.isfile(os.path.join(root_dir, \"y_gtzan_npy.npy\")):\n",
    "    X = np.load(\"x_gtzan_npy.npy\")\n",
    "    y = np.load(\"y_gtzan_npy.npy\")\n",
    "    print(\"Using saved training data..\")\n",
    "else: \n",
    "    X, y = read_data(gtzan_dir, genres, song_samples, to_melspectrogram, debug=False)\n",
    "    np.save('x_gtzan_npy.npy', X)\n",
    "    np.save('y_gtzan_npy.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2876a1d2-50b0-4dbd-aba8-bd2334db4a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(img, mean, std):\n",
    "    img = img/255.0\n",
    "    img[0] = (img[0] - mean[0]) / std[0]\n",
    "    img[1] = (img[1] - mean[1]) / std[1]\n",
    "    img[2] = (img[2] - mean[2]) / std[2]\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_train_test(X, y):\n",
    "    X_train, x_test_valid, y_train, y_test_valid = train_test_split(X,y, train_size=0.8)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(x_test_valid,y_test_valid, test_size=0.5)\n",
    "\n",
    "    X_train_rgb = []\n",
    "    X_val_rgb = []\n",
    "    X_test_rgb = []\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        X_train_sub = np.concatenate((X_train[i, :,:,:], X_train[i, :,:, :].reshape(128, 129, 1)), axis=2)\n",
    "        X_train_sub = np.concatenate((X_train_sub, X_train[i, :,:, 0].reshape(128, 129, 1)), axis=2)\n",
    "        X_train_sub = cv2.resize(X_train_sub, (224, 224))\n",
    "        X_train_sub = normalize(X_train_sub, mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "        X_train_rgb.append(X_train_sub)\n",
    "        \n",
    "    for i in range(X_val.shape[0]):\n",
    "        X_val_sub = np.concatenate((X_val[i, :,:,:], X_val[i, :,:, :].reshape(128, 129, 1)), axis=2)\n",
    "        X_val_sub = np.concatenate((X_val_sub, X_val[i, :,:, 0].reshape(128, 129, 1)), axis=2)\n",
    "        X_val_sub = cv2.resize(X_val_sub, (224, 224))\n",
    "        X_val_sub = normalize(X_val_sub, mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "        X_val_rgb.append(X_val_sub)\n",
    "        \n",
    "    for i in range(X_test.shape[0]):\n",
    "        X_test_sub = np.concatenate((X_test[i, :,:,:], X_test[i, :,:, :].reshape(128, 129, 1)), axis=2)\n",
    "        X_test_sub = np.concatenate((X_test_sub, X_test[i, :,:, 0].reshape(128, 129, 1)), axis=2)\n",
    "        X_test_sub = cv2.resize(X_test_sub, (224, 224))\n",
    "        X_test_sub = normalize(X_test_sub, mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        X_test_rgb.append(X_test_sub)\n",
    "\n",
    "    X_train_rgb = np.array(X_train_rgb, dtype=np.float32)\n",
    "    X_test_rgb = np.array(X_test_rgb, dtype=np.float32)\n",
    "    X_val_rgb = np.array(X_val_rgb, dtype=np.float32)\n",
    "\n",
    "    # print(\"shape before reshape\", X_train_rgb.shape, X_test_rgb.shape)\n",
    "    X_train_rgb = X_train_rgb.reshape(-1, 3, 224, 224)\n",
    "    X_val_rgb = X_val_rgb.reshape(-1, 3, 224, 224)\n",
    "    X_test_rgb = X_test_rgb.reshape(-1, 3, 224, 224)\n",
    "\n",
    "    return X_train_rgb, X_val_rgb, X_test_rgb, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d476eb71-e48c-4e6d-96c2-60726db72217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train,y_val, y_test = get_train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72358963-2661-4e8b-8d22-3a8ca76467c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val))\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33d3e1d-47d2-472c-91ad-93b3a9dab005",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f14630-17f0-4d61-a97b-635542231fe5",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7f78d9d-380a-42de-9dcc-99c1c58f5cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=256*14*14, out_features=1024)\n",
    "        self.bn5 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
    "        self.bn6 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b94eaa20-e23b-46d6-bd57-940b48d32d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = CNN().to(device)\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr,\n",
    "                    weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ae02212-25f1-4423-8855-e8c5c4ce6784",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100: Loss 1.904 Accuracy 0.303\n",
      "Epoch 1, Batch 200: Loss 1.529 Accuracy 0.443\n",
      "Epoch 1, Batch 300: Loss 1.291 Accuracy 0.555\n",
      "Epoch 1, Batch 400: Loss 1.210 Accuracy 0.578\n",
      "Epoch 1, Validation Accuracy: 0.616\n",
      "Epoch 2, Batch 100: Loss 1.048 Accuracy 0.640\n",
      "Epoch 2, Batch 200: Loss 1.053 Accuracy 0.644\n",
      "Epoch 2, Batch 300: Loss 1.032 Accuracy 0.647\n",
      "Epoch 2, Batch 400: Loss 1.020 Accuracy 0.655\n",
      "Epoch 2, Validation Accuracy: 0.678\n",
      "Epoch 3, Batch 100: Loss 0.920 Accuracy 0.692\n",
      "Epoch 3, Batch 200: Loss 0.917 Accuracy 0.682\n",
      "Epoch 3, Batch 300: Loss 0.886 Accuracy 0.694\n",
      "Epoch 3, Batch 400: Loss 0.932 Accuracy 0.682\n",
      "Epoch 3, Validation Accuracy: 0.649\n",
      "Epoch 4, Batch 100: Loss 0.846 Accuracy 0.724\n",
      "Epoch 4, Batch 200: Loss 0.831 Accuracy 0.709\n",
      "Epoch 4, Batch 300: Loss 0.860 Accuracy 0.711\n",
      "Epoch 4, Batch 400: Loss 0.822 Accuracy 0.724\n",
      "Epoch 4, Validation Accuracy: 0.717\n",
      "Epoch 5, Batch 100: Loss 0.775 Accuracy 0.738\n",
      "Epoch 5, Batch 200: Loss 0.770 Accuracy 0.738\n",
      "Epoch 5, Batch 300: Loss 0.804 Accuracy 0.724\n",
      "Epoch 5, Batch 400: Loss 0.791 Accuracy 0.734\n",
      "Epoch 5, Validation Accuracy: 0.719\n",
      "Epoch 6, Batch 100: Loss 0.686 Accuracy 0.759\n",
      "Epoch 6, Batch 200: Loss 0.731 Accuracy 0.745\n",
      "Epoch 6, Batch 300: Loss 0.778 Accuracy 0.734\n",
      "Epoch 6, Batch 400: Loss 0.760 Accuracy 0.740\n",
      "Epoch 6, Validation Accuracy: 0.750\n",
      "Epoch 7, Batch 100: Loss 0.632 Accuracy 0.792\n",
      "Epoch 7, Batch 200: Loss 0.707 Accuracy 0.766\n",
      "Epoch 7, Batch 300: Loss 0.683 Accuracy 0.763\n",
      "Epoch 7, Batch 400: Loss 0.704 Accuracy 0.760\n",
      "Epoch 7, Validation Accuracy: 0.746\n",
      "Epoch 8, Batch 100: Loss 0.588 Accuracy 0.797\n",
      "Epoch 8, Batch 200: Loss 0.651 Accuracy 0.776\n",
      "Epoch 8, Batch 300: Loss 0.645 Accuracy 0.786\n",
      "Epoch 8, Batch 400: Loss 0.686 Accuracy 0.770\n",
      "Epoch 8, Validation Accuracy: 0.781\n",
      "Epoch 9, Batch 100: Loss 0.512 Accuracy 0.836\n",
      "Epoch 9, Batch 200: Loss 0.623 Accuracy 0.787\n",
      "Epoch 9, Batch 300: Loss 0.671 Accuracy 0.779\n",
      "Epoch 9, Batch 400: Loss 0.657 Accuracy 0.774\n",
      "Epoch 9, Validation Accuracy: 0.753\n",
      "Epoch 10, Batch 100: Loss 0.549 Accuracy 0.813\n",
      "Epoch 10, Batch 200: Loss 0.591 Accuracy 0.804\n",
      "Epoch 10, Batch 300: Loss 0.581 Accuracy 0.805\n",
      "Epoch 10, Batch 400: Loss 0.603 Accuracy 0.796\n",
      "Epoch 10, Validation Accuracy: 0.778\n",
      "Epoch 11, Batch 100: Loss 0.474 Accuracy 0.844\n",
      "Epoch 11, Batch 200: Loss 0.516 Accuracy 0.826\n",
      "Epoch 11, Batch 300: Loss 0.563 Accuracy 0.809\n",
      "Epoch 11, Batch 400: Loss 0.602 Accuracy 0.787\n",
      "Epoch 11, Validation Accuracy: 0.775\n",
      "Epoch 12, Batch 100: Loss 0.456 Accuracy 0.851\n",
      "Epoch 12, Batch 200: Loss 0.508 Accuracy 0.824\n",
      "Epoch 12, Batch 300: Loss 0.569 Accuracy 0.803\n",
      "Epoch 12, Batch 400: Loss 0.605 Accuracy 0.802\n",
      "Epoch 12, Validation Accuracy: 0.784\n",
      "Epoch 13, Batch 100: Loss 0.431 Accuracy 0.859\n",
      "Epoch 13, Batch 200: Loss 0.474 Accuracy 0.832\n",
      "Epoch 13, Batch 300: Loss 0.552 Accuracy 0.813\n",
      "Epoch 13, Batch 400: Loss 0.526 Accuracy 0.828\n",
      "Epoch 13, Validation Accuracy: 0.770\n",
      "Epoch 14, Batch 100: Loss 0.433 Accuracy 0.855\n",
      "Epoch 14, Batch 200: Loss 0.465 Accuracy 0.845\n",
      "Epoch 14, Batch 300: Loss 0.500 Accuracy 0.828\n",
      "Epoch 14, Batch 400: Loss 0.513 Accuracy 0.825\n",
      "Epoch 14, Validation Accuracy: 0.775\n",
      "Epoch 15, Batch 100: Loss 0.416 Accuracy 0.860\n",
      "Epoch 15, Batch 200: Loss 0.445 Accuracy 0.854\n",
      "Epoch 15, Batch 300: Loss 0.499 Accuracy 0.834\n",
      "Epoch 15, Batch 400: Loss 0.487 Accuracy 0.835\n",
      "Epoch 15, Validation Accuracy: 0.789\n",
      "Epoch 16, Batch 100: Loss 0.414 Accuracy 0.862\n",
      "Epoch 16, Batch 200: Loss 0.448 Accuracy 0.853\n",
      "Epoch 16, Batch 300: Loss 0.470 Accuracy 0.842\n",
      "Epoch 16, Batch 400: Loss 0.516 Accuracy 0.833\n",
      "Epoch 16, Validation Accuracy: 0.777\n",
      "Epoch 17, Batch 100: Loss 0.395 Accuracy 0.870\n",
      "Epoch 17, Batch 200: Loss 0.439 Accuracy 0.853\n",
      "Epoch 17, Batch 300: Loss 0.448 Accuracy 0.849\n",
      "Epoch 17, Batch 400: Loss 0.473 Accuracy 0.833\n",
      "Epoch 17, Validation Accuracy: 0.801\n",
      "Epoch 18, Batch 100: Loss 0.379 Accuracy 0.877\n",
      "Epoch 18, Batch 200: Loss 0.408 Accuracy 0.864\n",
      "Epoch 18, Batch 300: Loss 0.429 Accuracy 0.858\n",
      "Epoch 18, Batch 400: Loss 0.466 Accuracy 0.837\n",
      "Epoch 18, Validation Accuracy: 0.807\n",
      "Epoch 19, Batch 100: Loss 0.336 Accuracy 0.883\n",
      "Epoch 19, Batch 200: Loss 0.362 Accuracy 0.881\n",
      "Epoch 19, Batch 300: Loss 0.432 Accuracy 0.853\n",
      "Epoch 19, Batch 400: Loss 0.431 Accuracy 0.854\n",
      "Epoch 19, Validation Accuracy: 0.805\n",
      "Epoch 20, Batch 100: Loss 0.339 Accuracy 0.883\n",
      "Epoch 20, Batch 200: Loss 0.369 Accuracy 0.879\n",
      "Epoch 20, Batch 300: Loss 0.380 Accuracy 0.863\n",
      "Epoch 20, Batch 400: Loss 0.438 Accuracy 0.854\n",
      "Epoch 20, Validation Accuracy: 0.788\n",
      "Epoch 21, Batch 100: Loss 0.353 Accuracy 0.885\n",
      "Epoch 21, Batch 200: Loss 0.342 Accuracy 0.887\n",
      "Epoch 21, Batch 300: Loss 0.392 Accuracy 0.868\n",
      "Epoch 21, Batch 400: Loss 0.444 Accuracy 0.848\n",
      "Epoch 21, Validation Accuracy: 0.803\n",
      "Epoch 22, Batch 100: Loss 0.326 Accuracy 0.891\n",
      "Epoch 22, Batch 200: Loss 0.337 Accuracy 0.889\n",
      "Epoch 22, Batch 300: Loss 0.377 Accuracy 0.873\n",
      "Epoch 22, Batch 400: Loss 0.410 Accuracy 0.858\n",
      "Epoch 22, Validation Accuracy: 0.798\n",
      "Epoch 23, Batch 100: Loss 0.325 Accuracy 0.885\n",
      "Epoch 23, Batch 200: Loss 0.343 Accuracy 0.892\n",
      "Epoch 23, Batch 300: Loss 0.382 Accuracy 0.865\n",
      "Epoch 23, Batch 400: Loss 0.390 Accuracy 0.871\n",
      "Epoch 23, Validation Accuracy: 0.802\n",
      "Epoch 24, Batch 100: Loss 0.317 Accuracy 0.896\n",
      "Epoch 24, Batch 200: Loss 0.335 Accuracy 0.885\n",
      "Epoch 24, Batch 300: Loss 0.355 Accuracy 0.877\n",
      "Epoch 24, Batch 400: Loss 0.384 Accuracy 0.873\n",
      "Epoch 24, Validation Accuracy: 0.811\n",
      "Epoch 25, Batch 100: Loss 0.308 Accuracy 0.902\n",
      "Epoch 25, Batch 200: Loss 0.308 Accuracy 0.897\n",
      "Epoch 25, Batch 300: Loss 0.375 Accuracy 0.879\n",
      "Epoch 25, Batch 400: Loss 0.386 Accuracy 0.871\n",
      "Epoch 25, Validation Accuracy: 0.798\n",
      "Epoch 26, Batch 100: Loss 0.302 Accuracy 0.904\n",
      "Epoch 26, Batch 200: Loss 0.309 Accuracy 0.899\n",
      "Epoch 26, Batch 300: Loss 0.375 Accuracy 0.871\n",
      "Epoch 26, Batch 400: Loss 0.361 Accuracy 0.876\n",
      "Epoch 26, Validation Accuracy: 0.806\n",
      "Epoch 27, Batch 100: Loss 0.336 Accuracy 0.887\n",
      "Epoch 27, Batch 200: Loss 0.314 Accuracy 0.896\n",
      "Epoch 27, Batch 300: Loss 0.334 Accuracy 0.891\n",
      "Epoch 27, Batch 400: Loss 0.361 Accuracy 0.875\n",
      "Epoch 27, Validation Accuracy: 0.809\n",
      "Epoch 28, Batch 100: Loss 0.277 Accuracy 0.904\n",
      "Epoch 28, Batch 200: Loss 0.326 Accuracy 0.894\n",
      "Epoch 28, Batch 300: Loss 0.334 Accuracy 0.894\n",
      "Epoch 28, Batch 400: Loss 0.376 Accuracy 0.877\n",
      "Epoch 28, Validation Accuracy: 0.806\n",
      "Epoch 29, Batch 100: Loss 0.306 Accuracy 0.900\n",
      "Epoch 29, Batch 200: Loss 0.295 Accuracy 0.908\n",
      "Epoch 29, Batch 300: Loss 0.327 Accuracy 0.890\n",
      "Epoch 29, Batch 400: Loss 0.361 Accuracy 0.881\n",
      "Epoch 29, Validation Accuracy: 0.801\n",
      "Epoch 30, Batch 100: Loss 0.276 Accuracy 0.912\n",
      "Epoch 30, Batch 200: Loss 0.303 Accuracy 0.897\n",
      "Epoch 30, Batch 300: Loss 0.329 Accuracy 0.890\n",
      "Epoch 30, Batch 400: Loss 0.388 Accuracy 0.873\n",
      "Epoch 30, Validation Accuracy: 0.802\n",
      "Epoch 31, Batch 100: Loss 0.276 Accuracy 0.914\n",
      "Epoch 31, Batch 200: Loss 0.270 Accuracy 0.912\n",
      "Epoch 31, Batch 300: Loss 0.328 Accuracy 0.887\n",
      "Epoch 31, Batch 400: Loss 0.343 Accuracy 0.885\n",
      "Epoch 31, Validation Accuracy: 0.812\n",
      "Epoch 32, Batch 100: Loss 0.264 Accuracy 0.912\n",
      "Epoch 32, Batch 200: Loss 0.287 Accuracy 0.903\n",
      "Epoch 32, Batch 300: Loss 0.319 Accuracy 0.892\n",
      "Epoch 32, Batch 400: Loss 0.330 Accuracy 0.891\n",
      "Epoch 32, Validation Accuracy: 0.807\n",
      "Epoch 33, Batch 100: Loss 0.298 Accuracy 0.900\n",
      "Epoch 33, Batch 200: Loss 0.283 Accuracy 0.910\n",
      "Epoch 33, Batch 300: Loss 0.314 Accuracy 0.896\n",
      "Epoch 33, Batch 400: Loss 0.349 Accuracy 0.882\n",
      "Epoch 33, Validation Accuracy: 0.813\n",
      "Epoch 34, Batch 100: Loss 0.258 Accuracy 0.916\n",
      "Epoch 34, Batch 200: Loss 0.305 Accuracy 0.897\n",
      "Epoch 34, Batch 300: Loss 0.366 Accuracy 0.872\n",
      "Epoch 34, Batch 400: Loss 0.343 Accuracy 0.886\n",
      "Epoch 34, Validation Accuracy: 0.807\n",
      "Epoch 35, Batch 100: Loss 0.257 Accuracy 0.912\n",
      "Epoch 35, Batch 200: Loss 0.289 Accuracy 0.913\n",
      "Epoch 35, Batch 300: Loss 0.309 Accuracy 0.896\n",
      "Epoch 35, Batch 400: Loss 0.306 Accuracy 0.895\n",
      "Epoch 35, Validation Accuracy: 0.809\n",
      "Epoch 36, Batch 100: Loss 0.277 Accuracy 0.910\n",
      "Epoch 36, Batch 200: Loss 0.284 Accuracy 0.908\n",
      "Epoch 36, Batch 300: Loss 0.317 Accuracy 0.889\n",
      "Epoch 36, Batch 400: Loss 0.294 Accuracy 0.900\n",
      "Epoch 36, Validation Accuracy: 0.807\n",
      "Epoch 37, Batch 100: Loss 0.237 Accuracy 0.921\n",
      "Epoch 37, Batch 200: Loss 0.281 Accuracy 0.902\n",
      "Epoch 37, Batch 300: Loss 0.327 Accuracy 0.901\n",
      "Epoch 37, Batch 400: Loss 0.351 Accuracy 0.882\n",
      "Epoch 37, Validation Accuracy: 0.805\n",
      "Epoch 38, Batch 100: Loss 0.265 Accuracy 0.912\n",
      "Epoch 38, Batch 200: Loss 0.260 Accuracy 0.919\n",
      "Epoch 38, Batch 300: Loss 0.281 Accuracy 0.907\n",
      "Epoch 38, Batch 400: Loss 0.326 Accuracy 0.892\n",
      "Epoch 38, Validation Accuracy: 0.807\n",
      "Epoch 39, Batch 100: Loss 0.276 Accuracy 0.913\n",
      "Epoch 39, Batch 200: Loss 0.282 Accuracy 0.907\n",
      "Epoch 39, Batch 300: Loss 0.315 Accuracy 0.897\n",
      "Epoch 39, Batch 400: Loss 0.302 Accuracy 0.905\n",
      "Epoch 39, Validation Accuracy: 0.810\n",
      "Epoch 40, Batch 100: Loss 0.255 Accuracy 0.919\n",
      "Epoch 40, Batch 200: Loss 0.271 Accuracy 0.908\n",
      "Epoch 40, Batch 300: Loss 0.290 Accuracy 0.902\n",
      "Epoch 40, Batch 400: Loss 0.339 Accuracy 0.884\n",
      "Epoch 40, Validation Accuracy: 0.803\n",
      "Epoch 41, Batch 100: Loss 0.248 Accuracy 0.921\n",
      "Epoch 41, Batch 200: Loss 0.250 Accuracy 0.924\n",
      "Epoch 41, Batch 300: Loss 0.267 Accuracy 0.909\n",
      "Epoch 41, Batch 400: Loss 0.315 Accuracy 0.894\n",
      "Epoch 41, Validation Accuracy: 0.807\n",
      "Epoch 42, Batch 100: Loss 0.252 Accuracy 0.916\n",
      "Epoch 42, Batch 200: Loss 0.266 Accuracy 0.909\n",
      "Epoch 42, Batch 300: Loss 0.290 Accuracy 0.906\n",
      "Epoch 42, Batch 400: Loss 0.338 Accuracy 0.884\n",
      "Epoch 42, Validation Accuracy: 0.816\n",
      "Epoch 43, Batch 100: Loss 0.236 Accuracy 0.920\n",
      "Epoch 43, Batch 200: Loss 0.270 Accuracy 0.911\n",
      "Epoch 43, Batch 300: Loss 0.289 Accuracy 0.900\n",
      "Epoch 43, Batch 400: Loss 0.338 Accuracy 0.885\n",
      "Epoch 43, Validation Accuracy: 0.807\n",
      "Epoch 44, Batch 100: Loss 0.274 Accuracy 0.910\n",
      "Epoch 44, Batch 200: Loss 0.262 Accuracy 0.911\n",
      "Epoch 44, Batch 300: Loss 0.279 Accuracy 0.905\n",
      "Epoch 44, Batch 400: Loss 0.338 Accuracy 0.892\n",
      "Epoch 44, Validation Accuracy: 0.815\n",
      "Epoch 45, Batch 100: Loss 0.256 Accuracy 0.913\n",
      "Epoch 45, Batch 200: Loss 0.258 Accuracy 0.917\n",
      "Epoch 45, Batch 300: Loss 0.285 Accuracy 0.909\n",
      "Epoch 45, Batch 400: Loss 0.312 Accuracy 0.895\n",
      "Epoch 45, Validation Accuracy: 0.825\n",
      "Epoch 46, Batch 100: Loss 0.254 Accuracy 0.914\n",
      "Epoch 46, Batch 200: Loss 0.241 Accuracy 0.920\n",
      "Epoch 46, Batch 300: Loss 0.301 Accuracy 0.899\n",
      "Epoch 46, Batch 400: Loss 0.318 Accuracy 0.894\n",
      "Epoch 46, Validation Accuracy: 0.798\n",
      "Epoch 47, Batch 100: Loss 0.264 Accuracy 0.906\n",
      "Epoch 47, Batch 200: Loss 0.280 Accuracy 0.908\n",
      "Epoch 47, Batch 300: Loss 0.292 Accuracy 0.905\n",
      "Epoch 47, Batch 400: Loss 0.314 Accuracy 0.894\n",
      "Epoch 47, Validation Accuracy: 0.817\n",
      "Epoch 48, Batch 100: Loss 0.233 Accuracy 0.922\n",
      "Epoch 48, Batch 200: Loss 0.242 Accuracy 0.919\n",
      "Epoch 48, Batch 300: Loss 0.269 Accuracy 0.912\n",
      "Epoch 48, Batch 400: Loss 0.309 Accuracy 0.903\n",
      "Epoch 48, Validation Accuracy: 0.811\n",
      "Epoch 49, Batch 100: Loss 0.248 Accuracy 0.923\n",
      "Epoch 49, Batch 200: Loss 0.246 Accuracy 0.918\n",
      "Epoch 49, Batch 300: Loss 0.279 Accuracy 0.907\n",
      "Epoch 49, Batch 400: Loss 0.330 Accuracy 0.894\n",
      "Epoch 49, Validation Accuracy: 0.791\n",
      "Epoch 50, Batch 100: Loss 0.256 Accuracy 0.919\n",
      "Epoch 50, Batch 200: Loss 0.259 Accuracy 0.912\n",
      "Epoch 50, Batch 300: Loss 0.312 Accuracy 0.897\n",
      "Epoch 50, Batch 400: Loss 0.291 Accuracy 0.900\n",
      "Epoch 50, Validation Accuracy: 0.809\n"
     ]
    }
   ],
   "source": [
    "#Trianing + Validation\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}: Loss {running_loss/100:.3f} Accuracy {correct / total:.3f}\")\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            \n",
    "    #validation \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            if device.type == 'cuda':\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.type(torch.LongTensor).cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "606bf72e-288a-4b2e-bd12-a73071da2332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 0.823\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\" Test Accuracy: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fddb6d-5419-4199-bbb8-a06edd23fd3e",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e2b455d-e529-40b5-8202-e85bea1581af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ktang2/.conda/envs/NN/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ktang2/.conda/envs/NN/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "net = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "new_fc = nn.Sequential(*list(net.fc.children())[:-1] + [nn.Linear(2048, 10)])\n",
    "net.fc = new_fc\n",
    "net = net.to(device)\n",
    "# net = net.type(torch.cuda.DoubleTensor)\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr,\n",
    "                    weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf15d150-98ac-4db5-acc0-814e61ebbd65",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100: Loss 1.909 Accuracy 0.309\n",
      "Epoch 1, Batch 200: Loss 1.635 Accuracy 0.422\n",
      "Epoch 1, Batch 300: Loss 1.565 Accuracy 0.449\n",
      "Epoch 1, Batch 400: Loss 1.453 Accuracy 0.490\n",
      "Epoch 1, Validation Accuracy: 0.477\n",
      "Epoch 2, Batch 100: Loss 1.412 Accuracy 0.500\n",
      "Epoch 2, Batch 200: Loss 1.367 Accuracy 0.527\n",
      "Epoch 2, Batch 300: Loss 1.370 Accuracy 0.513\n",
      "Epoch 2, Batch 400: Loss 1.356 Accuracy 0.527\n",
      "Epoch 2, Validation Accuracy: 0.507\n",
      "Epoch 3, Batch 100: Loss 1.309 Accuracy 0.550\n",
      "Epoch 3, Batch 200: Loss 1.334 Accuracy 0.537\n",
      "Epoch 3, Batch 300: Loss 1.307 Accuracy 0.556\n",
      "Epoch 3, Batch 400: Loss 1.333 Accuracy 0.531\n",
      "Epoch 3, Validation Accuracy: 0.522\n",
      "Epoch 4, Batch 100: Loss 1.265 Accuracy 0.557\n",
      "Epoch 4, Batch 200: Loss 1.301 Accuracy 0.553\n",
      "Epoch 4, Batch 300: Loss 1.272 Accuracy 0.568\n",
      "Epoch 4, Batch 400: Loss 1.309 Accuracy 0.548\n",
      "Epoch 4, Validation Accuracy: 0.529\n",
      "Epoch 5, Batch 100: Loss 1.219 Accuracy 0.579\n",
      "Epoch 5, Batch 200: Loss 1.258 Accuracy 0.560\n",
      "Epoch 5, Batch 300: Loss 1.268 Accuracy 0.562\n",
      "Epoch 5, Batch 400: Loss 1.273 Accuracy 0.560\n",
      "Epoch 5, Validation Accuracy: 0.534\n",
      "Epoch 6, Batch 100: Loss 1.271 Accuracy 0.576\n",
      "Epoch 6, Batch 200: Loss 1.219 Accuracy 0.573\n",
      "Epoch 6, Batch 300: Loss 1.225 Accuracy 0.578\n",
      "Epoch 6, Batch 400: Loss 1.255 Accuracy 0.566\n",
      "Epoch 6, Validation Accuracy: 0.549\n",
      "Epoch 7, Batch 100: Loss 1.223 Accuracy 0.574\n",
      "Epoch 7, Batch 200: Loss 1.240 Accuracy 0.569\n",
      "Epoch 7, Batch 300: Loss 1.205 Accuracy 0.585\n",
      "Epoch 7, Batch 400: Loss 1.288 Accuracy 0.556\n",
      "Epoch 7, Validation Accuracy: 0.559\n",
      "Epoch 8, Batch 100: Loss 1.229 Accuracy 0.573\n",
      "Epoch 8, Batch 200: Loss 1.206 Accuracy 0.581\n",
      "Epoch 8, Batch 300: Loss 1.204 Accuracy 0.588\n",
      "Epoch 8, Batch 400: Loss 1.198 Accuracy 0.583\n",
      "Epoch 8, Validation Accuracy: 0.546\n",
      "Epoch 9, Batch 100: Loss 1.203 Accuracy 0.578\n",
      "Epoch 9, Batch 200: Loss 1.199 Accuracy 0.586\n",
      "Epoch 9, Batch 300: Loss 1.177 Accuracy 0.600\n",
      "Epoch 9, Batch 400: Loss 1.222 Accuracy 0.577\n",
      "Epoch 9, Validation Accuracy: 0.568\n",
      "Epoch 10, Batch 100: Loss 1.159 Accuracy 0.592\n",
      "Epoch 10, Batch 200: Loss 1.169 Accuracy 0.610\n",
      "Epoch 10, Batch 300: Loss 1.192 Accuracy 0.592\n",
      "Epoch 10, Batch 400: Loss 1.223 Accuracy 0.581\n",
      "Epoch 10, Validation Accuracy: 0.555\n",
      "Epoch 11, Batch 100: Loss 1.171 Accuracy 0.595\n",
      "Epoch 11, Batch 200: Loss 1.142 Accuracy 0.605\n",
      "Epoch 11, Batch 300: Loss 1.193 Accuracy 0.594\n",
      "Epoch 11, Batch 400: Loss 1.161 Accuracy 0.601\n",
      "Epoch 11, Validation Accuracy: 0.569\n",
      "Epoch 12, Batch 100: Loss 1.187 Accuracy 0.588\n",
      "Epoch 12, Batch 200: Loss 1.120 Accuracy 0.609\n",
      "Epoch 12, Batch 300: Loss 1.154 Accuracy 0.604\n",
      "Epoch 12, Batch 400: Loss 1.159 Accuracy 0.593\n",
      "Epoch 12, Validation Accuracy: 0.576\n",
      "Epoch 13, Batch 100: Loss 1.106 Accuracy 0.625\n",
      "Epoch 13, Batch 200: Loss 1.140 Accuracy 0.608\n",
      "Epoch 13, Batch 300: Loss 1.147 Accuracy 0.608\n",
      "Epoch 13, Batch 400: Loss 1.180 Accuracy 0.590\n",
      "Epoch 13, Validation Accuracy: 0.545\n",
      "Epoch 14, Batch 100: Loss 1.137 Accuracy 0.605\n",
      "Epoch 14, Batch 200: Loss 1.115 Accuracy 0.619\n",
      "Epoch 14, Batch 300: Loss 1.076 Accuracy 0.627\n",
      "Epoch 14, Batch 400: Loss 1.134 Accuracy 0.609\n",
      "Epoch 14, Validation Accuracy: 0.556\n",
      "Epoch 15, Batch 100: Loss 1.122 Accuracy 0.615\n",
      "Epoch 15, Batch 200: Loss 1.102 Accuracy 0.631\n",
      "Epoch 15, Batch 300: Loss 1.098 Accuracy 0.619\n",
      "Epoch 15, Batch 400: Loss 1.126 Accuracy 0.610\n",
      "Epoch 15, Validation Accuracy: 0.556\n",
      "Epoch 16, Batch 100: Loss 1.116 Accuracy 0.620\n",
      "Epoch 16, Batch 200: Loss 1.176 Accuracy 0.593\n",
      "Epoch 16, Batch 300: Loss 1.136 Accuracy 0.619\n",
      "Epoch 16, Batch 400: Loss 1.129 Accuracy 0.603\n",
      "Epoch 16, Validation Accuracy: 0.582\n",
      "Epoch 17, Batch 100: Loss 1.088 Accuracy 0.623\n",
      "Epoch 17, Batch 200: Loss 1.122 Accuracy 0.616\n",
      "Epoch 17, Batch 300: Loss 1.106 Accuracy 0.623\n",
      "Epoch 17, Batch 400: Loss 1.127 Accuracy 0.612\n",
      "Epoch 17, Validation Accuracy: 0.558\n",
      "Epoch 18, Batch 100: Loss 1.092 Accuracy 0.616\n",
      "Epoch 18, Batch 200: Loss 1.080 Accuracy 0.624\n",
      "Epoch 18, Batch 300: Loss 1.137 Accuracy 0.606\n",
      "Epoch 18, Batch 400: Loss 1.160 Accuracy 0.600\n",
      "Epoch 18, Validation Accuracy: 0.583\n",
      "Epoch 19, Batch 100: Loss 1.106 Accuracy 0.625\n",
      "Epoch 19, Batch 200: Loss 1.077 Accuracy 0.633\n",
      "Epoch 19, Batch 300: Loss 1.135 Accuracy 0.611\n",
      "Epoch 19, Batch 400: Loss 1.103 Accuracy 0.621\n",
      "Epoch 19, Validation Accuracy: 0.579\n",
      "Epoch 20, Batch 100: Loss 1.103 Accuracy 0.612\n",
      "Epoch 20, Batch 200: Loss 1.083 Accuracy 0.635\n",
      "Epoch 20, Batch 300: Loss 1.089 Accuracy 0.627\n",
      "Epoch 20, Batch 400: Loss 1.140 Accuracy 0.607\n",
      "Epoch 20, Validation Accuracy: 0.577\n",
      "Epoch 21, Batch 100: Loss 1.102 Accuracy 0.629\n",
      "Epoch 21, Batch 200: Loss 1.058 Accuracy 0.640\n",
      "Epoch 21, Batch 300: Loss 1.132 Accuracy 0.604\n",
      "Epoch 21, Batch 400: Loss 1.092 Accuracy 0.623\n",
      "Epoch 21, Validation Accuracy: 0.581\n",
      "Epoch 22, Batch 100: Loss 1.071 Accuracy 0.627\n",
      "Epoch 22, Batch 200: Loss 1.093 Accuracy 0.620\n",
      "Epoch 22, Batch 300: Loss 1.086 Accuracy 0.630\n",
      "Epoch 22, Batch 400: Loss 1.108 Accuracy 0.622\n",
      "Epoch 22, Validation Accuracy: 0.585\n",
      "Epoch 23, Batch 100: Loss 1.093 Accuracy 0.625\n",
      "Epoch 23, Batch 200: Loss 1.033 Accuracy 0.653\n",
      "Epoch 23, Batch 300: Loss 1.083 Accuracy 0.634\n",
      "Epoch 23, Batch 400: Loss 1.113 Accuracy 0.617\n",
      "Epoch 23, Validation Accuracy: 0.568\n",
      "Epoch 24, Batch 100: Loss 1.071 Accuracy 0.622\n",
      "Epoch 24, Batch 200: Loss 1.083 Accuracy 0.623\n",
      "Epoch 24, Batch 300: Loss 1.093 Accuracy 0.634\n",
      "Epoch 24, Batch 400: Loss 1.089 Accuracy 0.622\n",
      "Epoch 24, Validation Accuracy: 0.542\n",
      "Epoch 25, Batch 100: Loss 1.068 Accuracy 0.632\n",
      "Epoch 25, Batch 200: Loss 1.079 Accuracy 0.643\n",
      "Epoch 25, Batch 300: Loss 1.097 Accuracy 0.622\n",
      "Epoch 25, Batch 400: Loss 1.070 Accuracy 0.635\n",
      "Epoch 25, Validation Accuracy: 0.556\n",
      "Epoch 26, Batch 100: Loss 1.081 Accuracy 0.627\n",
      "Epoch 26, Batch 200: Loss 1.061 Accuracy 0.632\n",
      "Epoch 26, Batch 300: Loss 1.087 Accuracy 0.632\n",
      "Epoch 26, Batch 400: Loss 1.045 Accuracy 0.643\n",
      "Epoch 26, Validation Accuracy: 0.542\n",
      "Epoch 27, Batch 100: Loss 1.107 Accuracy 0.615\n",
      "Epoch 27, Batch 200: Loss 1.038 Accuracy 0.650\n",
      "Epoch 27, Batch 300: Loss 1.065 Accuracy 0.635\n",
      "Epoch 27, Batch 400: Loss 1.065 Accuracy 0.621\n",
      "Epoch 27, Validation Accuracy: 0.592\n",
      "Epoch 28, Batch 100: Loss 1.056 Accuracy 0.642\n",
      "Epoch 28, Batch 200: Loss 1.055 Accuracy 0.634\n",
      "Epoch 28, Batch 300: Loss 1.035 Accuracy 0.637\n",
      "Epoch 28, Batch 400: Loss 1.092 Accuracy 0.621\n",
      "Epoch 28, Validation Accuracy: 0.593\n",
      "Epoch 29, Batch 100: Loss 1.034 Accuracy 0.656\n",
      "Epoch 29, Batch 200: Loss 1.058 Accuracy 0.636\n",
      "Epoch 29, Batch 300: Loss 1.094 Accuracy 0.621\n",
      "Epoch 29, Batch 400: Loss 1.077 Accuracy 0.637\n",
      "Epoch 29, Validation Accuracy: 0.579\n",
      "Epoch 30, Batch 100: Loss 1.069 Accuracy 0.627\n",
      "Epoch 30, Batch 200: Loss 1.024 Accuracy 0.648\n",
      "Epoch 30, Batch 300: Loss 1.068 Accuracy 0.632\n",
      "Epoch 30, Batch 400: Loss 1.040 Accuracy 0.646\n",
      "Epoch 30, Validation Accuracy: 0.566\n",
      "Epoch 31, Batch 100: Loss 1.050 Accuracy 0.638\n",
      "Epoch 31, Batch 200: Loss 1.045 Accuracy 0.646\n",
      "Epoch 31, Batch 300: Loss 1.039 Accuracy 0.645\n",
      "Epoch 31, Batch 400: Loss 1.096 Accuracy 0.624\n",
      "Epoch 31, Validation Accuracy: 0.574\n",
      "Epoch 32, Batch 100: Loss 1.047 Accuracy 0.644\n",
      "Epoch 32, Batch 200: Loss 1.043 Accuracy 0.636\n",
      "Epoch 32, Batch 300: Loss 1.054 Accuracy 0.641\n",
      "Epoch 32, Batch 400: Loss 1.011 Accuracy 0.650\n",
      "Epoch 32, Validation Accuracy: 0.586\n",
      "Epoch 33, Batch 100: Loss 1.022 Accuracy 0.649\n",
      "Epoch 33, Batch 200: Loss 1.035 Accuracy 0.640\n",
      "Epoch 33, Batch 300: Loss 1.034 Accuracy 0.639\n",
      "Epoch 33, Batch 400: Loss 1.046 Accuracy 0.644\n",
      "Epoch 33, Validation Accuracy: 0.585\n",
      "Epoch 34, Batch 100: Loss 1.047 Accuracy 0.644\n",
      "Epoch 34, Batch 200: Loss 1.065 Accuracy 0.637\n",
      "Epoch 34, Batch 300: Loss 1.056 Accuracy 0.637\n",
      "Epoch 34, Batch 400: Loss 1.034 Accuracy 0.636\n",
      "Epoch 34, Validation Accuracy: 0.585\n",
      "Epoch 35, Batch 100: Loss 1.014 Accuracy 0.658\n",
      "Epoch 35, Batch 200: Loss 1.025 Accuracy 0.655\n",
      "Epoch 35, Batch 300: Loss 1.030 Accuracy 0.649\n",
      "Epoch 35, Batch 400: Loss 1.034 Accuracy 0.641\n",
      "Epoch 35, Validation Accuracy: 0.582\n",
      "Epoch 36, Batch 100: Loss 1.032 Accuracy 0.645\n",
      "Epoch 36, Batch 200: Loss 1.024 Accuracy 0.642\n",
      "Epoch 36, Batch 300: Loss 1.021 Accuracy 0.651\n",
      "Epoch 36, Batch 400: Loss 1.033 Accuracy 0.642\n",
      "Epoch 36, Validation Accuracy: 0.575\n",
      "Epoch 37, Batch 100: Loss 0.996 Accuracy 0.663\n",
      "Epoch 37, Batch 200: Loss 1.048 Accuracy 0.640\n",
      "Epoch 37, Batch 300: Loss 1.034 Accuracy 0.648\n",
      "Epoch 37, Batch 400: Loss 1.056 Accuracy 0.645\n",
      "Epoch 37, Validation Accuracy: 0.582\n",
      "Epoch 38, Batch 100: Loss 0.987 Accuracy 0.661\n",
      "Epoch 38, Batch 200: Loss 1.008 Accuracy 0.648\n",
      "Epoch 38, Batch 300: Loss 1.051 Accuracy 0.640\n",
      "Epoch 38, Batch 400: Loss 1.072 Accuracy 0.636\n",
      "Epoch 38, Validation Accuracy: 0.597\n",
      "Epoch 39, Batch 100: Loss 0.976 Accuracy 0.663\n",
      "Epoch 39, Batch 200: Loss 1.022 Accuracy 0.652\n",
      "Epoch 39, Batch 300: Loss 1.020 Accuracy 0.651\n",
      "Epoch 39, Batch 400: Loss 1.011 Accuracy 0.646\n",
      "Epoch 39, Validation Accuracy: 0.585\n",
      "Epoch 40, Batch 100: Loss 1.018 Accuracy 0.645\n",
      "Epoch 40, Batch 200: Loss 1.038 Accuracy 0.641\n",
      "Epoch 40, Batch 300: Loss 1.029 Accuracy 0.642\n",
      "Epoch 40, Batch 400: Loss 1.007 Accuracy 0.648\n",
      "Epoch 40, Validation Accuracy: 0.562\n",
      "Epoch 41, Batch 100: Loss 1.043 Accuracy 0.635\n",
      "Epoch 41, Batch 200: Loss 1.004 Accuracy 0.651\n",
      "Epoch 41, Batch 300: Loss 1.050 Accuracy 0.638\n",
      "Epoch 41, Batch 400: Loss 1.038 Accuracy 0.642\n",
      "Epoch 41, Validation Accuracy: 0.572\n",
      "Epoch 42, Batch 100: Loss 0.964 Accuracy 0.661\n",
      "Epoch 42, Batch 200: Loss 1.015 Accuracy 0.647\n",
      "Epoch 42, Batch 300: Loss 1.011 Accuracy 0.645\n",
      "Epoch 42, Batch 400: Loss 1.004 Accuracy 0.661\n",
      "Epoch 42, Validation Accuracy: 0.598\n",
      "Epoch 43, Batch 100: Loss 0.992 Accuracy 0.665\n",
      "Epoch 43, Batch 200: Loss 1.011 Accuracy 0.654\n",
      "Epoch 43, Batch 300: Loss 0.998 Accuracy 0.653\n",
      "Epoch 43, Batch 400: Loss 1.049 Accuracy 0.638\n",
      "Epoch 43, Validation Accuracy: 0.583\n",
      "Epoch 44, Batch 100: Loss 0.992 Accuracy 0.663\n",
      "Epoch 44, Batch 200: Loss 1.034 Accuracy 0.643\n",
      "Epoch 44, Batch 300: Loss 1.014 Accuracy 0.644\n",
      "Epoch 44, Batch 400: Loss 0.997 Accuracy 0.657\n",
      "Epoch 44, Validation Accuracy: 0.581\n",
      "Epoch 45, Batch 100: Loss 0.969 Accuracy 0.669\n",
      "Epoch 45, Batch 200: Loss 0.974 Accuracy 0.665\n",
      "Epoch 45, Batch 300: Loss 0.994 Accuracy 0.657\n",
      "Epoch 45, Batch 400: Loss 1.045 Accuracy 0.646\n",
      "Epoch 45, Validation Accuracy: 0.597\n",
      "Epoch 46, Batch 100: Loss 1.004 Accuracy 0.662\n",
      "Epoch 46, Batch 200: Loss 0.990 Accuracy 0.672\n",
      "Epoch 46, Batch 300: Loss 1.014 Accuracy 0.647\n",
      "Epoch 46, Batch 400: Loss 1.012 Accuracy 0.658\n",
      "Epoch 46, Validation Accuracy: 0.615\n",
      "Epoch 47, Batch 100: Loss 0.969 Accuracy 0.669\n",
      "Epoch 47, Batch 200: Loss 1.011 Accuracy 0.649\n",
      "Epoch 47, Batch 300: Loss 0.998 Accuracy 0.655\n",
      "Epoch 47, Batch 400: Loss 0.993 Accuracy 0.666\n",
      "Epoch 47, Validation Accuracy: 0.598\n",
      "Epoch 48, Batch 100: Loss 0.996 Accuracy 0.659\n",
      "Epoch 48, Batch 200: Loss 1.014 Accuracy 0.648\n",
      "Epoch 48, Batch 300: Loss 1.033 Accuracy 0.643\n",
      "Epoch 48, Batch 400: Loss 1.003 Accuracy 0.654\n",
      "Epoch 48, Validation Accuracy: 0.604\n",
      "Epoch 49, Batch 100: Loss 0.962 Accuracy 0.672\n",
      "Epoch 49, Batch 200: Loss 0.996 Accuracy 0.657\n",
      "Epoch 49, Batch 300: Loss 0.989 Accuracy 0.655\n",
      "Epoch 49, Batch 400: Loss 0.990 Accuracy 0.659\n",
      "Epoch 49, Validation Accuracy: 0.613\n",
      "Epoch 50, Batch 100: Loss 0.942 Accuracy 0.669\n",
      "Epoch 50, Batch 200: Loss 0.972 Accuracy 0.674\n",
      "Epoch 50, Batch 300: Loss 0.991 Accuracy 0.657\n",
      "Epoch 50, Batch 400: Loss 1.027 Accuracy 0.642\n",
      "Epoch 50, Validation Accuracy: 0.596\n",
      "Epoch 51, Batch 100: Loss 0.951 Accuracy 0.668\n",
      "Epoch 51, Batch 200: Loss 0.995 Accuracy 0.656\n",
      "Epoch 51, Batch 300: Loss 0.969 Accuracy 0.678\n",
      "Epoch 51, Batch 400: Loss 1.007 Accuracy 0.651\n",
      "Epoch 51, Validation Accuracy: 0.598\n",
      "Epoch 52, Batch 100: Loss 0.954 Accuracy 0.675\n",
      "Epoch 52, Batch 200: Loss 1.008 Accuracy 0.651\n",
      "Epoch 52, Batch 300: Loss 0.994 Accuracy 0.660\n",
      "Epoch 52, Batch 400: Loss 1.003 Accuracy 0.652\n",
      "Epoch 52, Validation Accuracy: 0.594\n",
      "Epoch 53, Batch 100: Loss 0.976 Accuracy 0.665\n",
      "Epoch 53, Batch 200: Loss 1.002 Accuracy 0.655\n",
      "Epoch 53, Batch 300: Loss 0.982 Accuracy 0.657\n",
      "Epoch 53, Batch 400: Loss 0.996 Accuracy 0.662\n",
      "Epoch 53, Validation Accuracy: 0.593\n",
      "Epoch 54, Batch 100: Loss 0.932 Accuracy 0.681\n",
      "Epoch 54, Batch 200: Loss 0.982 Accuracy 0.663\n",
      "Epoch 54, Batch 300: Loss 1.004 Accuracy 0.652\n",
      "Epoch 54, Batch 400: Loss 0.992 Accuracy 0.659\n",
      "Epoch 54, Validation Accuracy: 0.586\n",
      "Epoch 55, Batch 100: Loss 0.953 Accuracy 0.673\n",
      "Epoch 55, Batch 200: Loss 1.056 Accuracy 0.634\n",
      "Epoch 55, Batch 300: Loss 0.980 Accuracy 0.655\n",
      "Epoch 55, Batch 400: Loss 1.025 Accuracy 0.652\n",
      "Epoch 55, Validation Accuracy: 0.599\n",
      "Epoch 56, Batch 100: Loss 0.955 Accuracy 0.670\n",
      "Epoch 56, Batch 200: Loss 1.013 Accuracy 0.648\n",
      "Epoch 56, Batch 300: Loss 0.950 Accuracy 0.682\n",
      "Epoch 56, Batch 400: Loss 1.009 Accuracy 0.654\n",
      "Epoch 56, Validation Accuracy: 0.586\n",
      "Epoch 57, Batch 100: Loss 0.951 Accuracy 0.674\n",
      "Epoch 57, Batch 200: Loss 1.009 Accuracy 0.655\n",
      "Epoch 57, Batch 300: Loss 0.988 Accuracy 0.656\n",
      "Epoch 57, Batch 400: Loss 0.945 Accuracy 0.683\n",
      "Epoch 57, Validation Accuracy: 0.612\n",
      "Epoch 58, Batch 100: Loss 0.983 Accuracy 0.661\n",
      "Epoch 58, Batch 200: Loss 0.978 Accuracy 0.672\n",
      "Epoch 58, Batch 300: Loss 0.968 Accuracy 0.683\n",
      "Epoch 58, Batch 400: Loss 0.951 Accuracy 0.677\n",
      "Epoch 58, Validation Accuracy: 0.556\n",
      "Epoch 59, Batch 100: Loss 0.985 Accuracy 0.652\n",
      "Epoch 59, Batch 200: Loss 1.033 Accuracy 0.647\n",
      "Epoch 59, Batch 300: Loss 0.957 Accuracy 0.670\n",
      "Epoch 59, Batch 400: Loss 1.014 Accuracy 0.649\n",
      "Epoch 59, Validation Accuracy: 0.591\n",
      "Epoch 60, Batch 100: Loss 0.984 Accuracy 0.663\n",
      "Epoch 60, Batch 200: Loss 0.999 Accuracy 0.656\n",
      "Epoch 60, Batch 300: Loss 0.992 Accuracy 0.662\n",
      "Epoch 60, Batch 400: Loss 0.929 Accuracy 0.681\n",
      "Epoch 60, Validation Accuracy: 0.582\n",
      "Epoch 61, Batch 100: Loss 0.974 Accuracy 0.666\n",
      "Epoch 61, Batch 200: Loss 1.006 Accuracy 0.649\n",
      "Epoch 61, Batch 300: Loss 0.931 Accuracy 0.682\n",
      "Epoch 61, Batch 400: Loss 0.980 Accuracy 0.674\n",
      "Epoch 61, Validation Accuracy: 0.606\n",
      "Epoch 62, Batch 100: Loss 0.959 Accuracy 0.669\n",
      "Epoch 62, Batch 200: Loss 0.974 Accuracy 0.663\n",
      "Epoch 62, Batch 300: Loss 1.003 Accuracy 0.648\n",
      "Epoch 62, Batch 400: Loss 0.991 Accuracy 0.657\n",
      "Epoch 62, Validation Accuracy: 0.601\n",
      "Epoch 63, Batch 100: Loss 0.948 Accuracy 0.677\n",
      "Epoch 63, Batch 200: Loss 0.973 Accuracy 0.667\n",
      "Epoch 63, Batch 300: Loss 1.010 Accuracy 0.647\n",
      "Epoch 63, Batch 400: Loss 1.009 Accuracy 0.645\n",
      "Epoch 63, Validation Accuracy: 0.605\n",
      "Epoch 64, Batch 100: Loss 0.936 Accuracy 0.681\n",
      "Epoch 64, Batch 200: Loss 0.942 Accuracy 0.680\n",
      "Epoch 64, Batch 300: Loss 0.993 Accuracy 0.656\n",
      "Epoch 64, Batch 400: Loss 1.026 Accuracy 0.643\n",
      "Epoch 64, Validation Accuracy: 0.587\n",
      "Epoch 65, Batch 100: Loss 0.946 Accuracy 0.670\n",
      "Epoch 65, Batch 200: Loss 0.979 Accuracy 0.670\n",
      "Epoch 65, Batch 300: Loss 1.004 Accuracy 0.657\n",
      "Epoch 65, Batch 400: Loss 0.969 Accuracy 0.664\n",
      "Epoch 65, Validation Accuracy: 0.592\n",
      "Epoch 66, Batch 100: Loss 0.914 Accuracy 0.693\n",
      "Epoch 66, Batch 200: Loss 0.992 Accuracy 0.661\n",
      "Epoch 66, Batch 300: Loss 0.980 Accuracy 0.655\n",
      "Epoch 66, Batch 400: Loss 0.970 Accuracy 0.669\n",
      "Epoch 66, Validation Accuracy: 0.605\n",
      "Epoch 67, Batch 100: Loss 0.995 Accuracy 0.664\n",
      "Epoch 67, Batch 200: Loss 0.973 Accuracy 0.669\n",
      "Epoch 67, Batch 300: Loss 0.945 Accuracy 0.675\n",
      "Epoch 67, Batch 400: Loss 0.973 Accuracy 0.662\n",
      "Epoch 67, Validation Accuracy: 0.595\n",
      "Epoch 68, Batch 100: Loss 0.924 Accuracy 0.681\n",
      "Epoch 68, Batch 200: Loss 0.975 Accuracy 0.669\n",
      "Epoch 68, Batch 300: Loss 1.033 Accuracy 0.649\n",
      "Epoch 68, Batch 400: Loss 0.940 Accuracy 0.686\n",
      "Epoch 68, Validation Accuracy: 0.565\n",
      "Epoch 69, Batch 100: Loss 0.942 Accuracy 0.674\n",
      "Epoch 69, Batch 200: Loss 0.969 Accuracy 0.664\n",
      "Epoch 69, Batch 300: Loss 0.999 Accuracy 0.659\n",
      "Epoch 69, Batch 400: Loss 0.970 Accuracy 0.670\n",
      "Epoch 69, Validation Accuracy: 0.602\n",
      "Epoch 70, Batch 100: Loss 0.974 Accuracy 0.664\n",
      "Epoch 70, Batch 200: Loss 0.994 Accuracy 0.668\n",
      "Epoch 70, Batch 300: Loss 0.951 Accuracy 0.683\n",
      "Epoch 70, Batch 400: Loss 0.973 Accuracy 0.664\n",
      "Epoch 70, Validation Accuracy: 0.601\n",
      "Epoch 71, Batch 100: Loss 0.934 Accuracy 0.684\n",
      "Epoch 71, Batch 200: Loss 0.930 Accuracy 0.680\n",
      "Epoch 71, Batch 300: Loss 0.936 Accuracy 0.682\n",
      "Epoch 71, Batch 400: Loss 0.980 Accuracy 0.662\n",
      "Epoch 71, Validation Accuracy: 0.613\n",
      "Epoch 72, Batch 100: Loss 0.921 Accuracy 0.686\n",
      "Epoch 72, Batch 200: Loss 1.005 Accuracy 0.656\n",
      "Epoch 72, Batch 300: Loss 0.960 Accuracy 0.676\n",
      "Epoch 72, Batch 400: Loss 0.941 Accuracy 0.677\n",
      "Epoch 72, Validation Accuracy: 0.591\n",
      "Epoch 73, Batch 100: Loss 0.906 Accuracy 0.692\n",
      "Epoch 73, Batch 200: Loss 0.969 Accuracy 0.670\n",
      "Epoch 73, Batch 300: Loss 0.957 Accuracy 0.675\n",
      "Epoch 73, Batch 400: Loss 0.969 Accuracy 0.666\n",
      "Epoch 73, Validation Accuracy: 0.604\n",
      "Epoch 74, Batch 100: Loss 0.980 Accuracy 0.658\n",
      "Epoch 74, Batch 200: Loss 0.981 Accuracy 0.666\n",
      "Epoch 74, Batch 300: Loss 0.927 Accuracy 0.678\n",
      "Epoch 74, Batch 400: Loss 1.008 Accuracy 0.658\n",
      "Epoch 74, Validation Accuracy: 0.604\n",
      "Epoch 75, Batch 100: Loss 0.995 Accuracy 0.653\n",
      "Epoch 75, Batch 200: Loss 0.941 Accuracy 0.675\n",
      "Epoch 75, Batch 300: Loss 0.987 Accuracy 0.662\n",
      "Epoch 75, Batch 400: Loss 0.981 Accuracy 0.666\n",
      "Epoch 75, Validation Accuracy: 0.602\n",
      "Epoch 76, Batch 100: Loss 0.936 Accuracy 0.679\n",
      "Epoch 76, Batch 200: Loss 0.942 Accuracy 0.680\n",
      "Epoch 76, Batch 300: Loss 0.949 Accuracy 0.672\n",
      "Epoch 76, Batch 400: Loss 0.982 Accuracy 0.662\n",
      "Epoch 76, Validation Accuracy: 0.601\n",
      "Epoch 77, Batch 100: Loss 0.943 Accuracy 0.673\n",
      "Epoch 77, Batch 200: Loss 0.948 Accuracy 0.675\n",
      "Epoch 77, Batch 300: Loss 0.920 Accuracy 0.690\n",
      "Epoch 77, Batch 400: Loss 0.989 Accuracy 0.666\n",
      "Epoch 77, Validation Accuracy: 0.604\n",
      "Epoch 78, Batch 100: Loss 0.961 Accuracy 0.668\n",
      "Epoch 78, Batch 200: Loss 0.940 Accuracy 0.673\n",
      "Epoch 78, Batch 300: Loss 0.911 Accuracy 0.688\n",
      "Epoch 78, Batch 400: Loss 0.933 Accuracy 0.691\n",
      "Epoch 78, Validation Accuracy: 0.614\n",
      "Epoch 79, Batch 100: Loss 0.894 Accuracy 0.700\n",
      "Epoch 79, Batch 200: Loss 0.992 Accuracy 0.665\n",
      "Epoch 79, Batch 300: Loss 0.983 Accuracy 0.669\n",
      "Epoch 79, Batch 400: Loss 0.992 Accuracy 0.665\n",
      "Epoch 79, Validation Accuracy: 0.618\n",
      "Epoch 80, Batch 100: Loss 0.928 Accuracy 0.684\n",
      "Epoch 80, Batch 200: Loss 0.943 Accuracy 0.669\n",
      "Epoch 80, Batch 300: Loss 0.922 Accuracy 0.683\n",
      "Epoch 80, Batch 400: Loss 0.965 Accuracy 0.663\n",
      "Epoch 80, Validation Accuracy: 0.599\n",
      "Epoch 81, Batch 100: Loss 0.921 Accuracy 0.681\n",
      "Epoch 81, Batch 200: Loss 0.902 Accuracy 0.693\n",
      "Epoch 81, Batch 300: Loss 0.944 Accuracy 0.678\n",
      "Epoch 81, Batch 400: Loss 0.977 Accuracy 0.670\n",
      "Epoch 81, Validation Accuracy: 0.612\n",
      "Epoch 82, Batch 100: Loss 0.977 Accuracy 0.666\n",
      "Epoch 82, Batch 200: Loss 0.964 Accuracy 0.668\n",
      "Epoch 82, Batch 300: Loss 0.939 Accuracy 0.677\n",
      "Epoch 82, Batch 400: Loss 0.966 Accuracy 0.671\n",
      "Epoch 82, Validation Accuracy: 0.599\n",
      "Epoch 83, Batch 100: Loss 0.919 Accuracy 0.687\n",
      "Epoch 83, Batch 200: Loss 0.931 Accuracy 0.679\n",
      "Epoch 83, Batch 300: Loss 0.965 Accuracy 0.669\n",
      "Epoch 83, Batch 400: Loss 0.929 Accuracy 0.682\n",
      "Epoch 83, Validation Accuracy: 0.583\n",
      "Epoch 84, Batch 100: Loss 0.992 Accuracy 0.659\n",
      "Epoch 84, Batch 200: Loss 0.890 Accuracy 0.700\n",
      "Epoch 84, Batch 300: Loss 0.940 Accuracy 0.680\n",
      "Epoch 84, Batch 400: Loss 1.005 Accuracy 0.655\n",
      "Epoch 84, Validation Accuracy: 0.596\n",
      "Epoch 85, Batch 100: Loss 0.928 Accuracy 0.692\n",
      "Epoch 85, Batch 200: Loss 0.959 Accuracy 0.672\n",
      "Epoch 85, Batch 300: Loss 0.915 Accuracy 0.683\n",
      "Epoch 85, Batch 400: Loss 0.942 Accuracy 0.683\n",
      "Epoch 85, Validation Accuracy: 0.591\n",
      "Epoch 86, Batch 100: Loss 0.957 Accuracy 0.671\n",
      "Epoch 86, Batch 200: Loss 0.916 Accuracy 0.694\n",
      "Epoch 86, Batch 300: Loss 0.972 Accuracy 0.669\n",
      "Epoch 86, Batch 400: Loss 0.952 Accuracy 0.669\n",
      "Epoch 86, Validation Accuracy: 0.601\n",
      "Epoch 87, Batch 100: Loss 0.931 Accuracy 0.678\n",
      "Epoch 87, Batch 200: Loss 0.966 Accuracy 0.662\n",
      "Epoch 87, Batch 300: Loss 0.917 Accuracy 0.686\n",
      "Epoch 87, Batch 400: Loss 0.966 Accuracy 0.665\n",
      "Epoch 87, Validation Accuracy: 0.597\n",
      "Epoch 88, Batch 100: Loss 0.911 Accuracy 0.696\n",
      "Epoch 88, Batch 200: Loss 0.955 Accuracy 0.675\n",
      "Epoch 88, Batch 300: Loss 0.914 Accuracy 0.695\n",
      "Epoch 88, Batch 400: Loss 0.913 Accuracy 0.690\n",
      "Epoch 88, Validation Accuracy: 0.605\n",
      "Epoch 89, Batch 100: Loss 0.911 Accuracy 0.692\n",
      "Epoch 89, Batch 200: Loss 0.937 Accuracy 0.671\n",
      "Epoch 89, Batch 300: Loss 0.966 Accuracy 0.653\n",
      "Epoch 89, Batch 400: Loss 0.938 Accuracy 0.674\n",
      "Epoch 89, Validation Accuracy: 0.607\n",
      "Epoch 90, Batch 100: Loss 0.972 Accuracy 0.662\n",
      "Epoch 90, Batch 200: Loss 0.931 Accuracy 0.686\n",
      "Epoch 90, Batch 300: Loss 0.977 Accuracy 0.672\n",
      "Epoch 90, Batch 400: Loss 0.932 Accuracy 0.683\n",
      "Epoch 90, Validation Accuracy: 0.607\n",
      "Epoch 91, Batch 100: Loss 0.921 Accuracy 0.684\n",
      "Epoch 91, Batch 200: Loss 0.955 Accuracy 0.670\n",
      "Epoch 91, Batch 300: Loss 0.940 Accuracy 0.679\n",
      "Epoch 91, Batch 400: Loss 0.947 Accuracy 0.683\n",
      "Epoch 91, Validation Accuracy: 0.609\n",
      "Epoch 92, Batch 100: Loss 0.921 Accuracy 0.691\n",
      "Epoch 92, Batch 200: Loss 0.966 Accuracy 0.671\n",
      "Epoch 92, Batch 300: Loss 0.955 Accuracy 0.667\n",
      "Epoch 92, Batch 400: Loss 0.945 Accuracy 0.672\n",
      "Epoch 92, Validation Accuracy: 0.605\n",
      "Epoch 93, Batch 100: Loss 0.958 Accuracy 0.678\n",
      "Epoch 93, Batch 200: Loss 0.941 Accuracy 0.683\n",
      "Epoch 93, Batch 300: Loss 0.979 Accuracy 0.661\n",
      "Epoch 93, Batch 400: Loss 0.905 Accuracy 0.680\n",
      "Epoch 93, Validation Accuracy: 0.619\n",
      "Epoch 94, Batch 100: Loss 0.906 Accuracy 0.697\n",
      "Epoch 94, Batch 200: Loss 0.927 Accuracy 0.682\n",
      "Epoch 94, Batch 300: Loss 0.976 Accuracy 0.666\n",
      "Epoch 94, Batch 400: Loss 0.949 Accuracy 0.686\n",
      "Epoch 94, Validation Accuracy: 0.613\n",
      "Epoch 95, Batch 100: Loss 0.909 Accuracy 0.692\n",
      "Epoch 95, Batch 200: Loss 0.920 Accuracy 0.689\n",
      "Epoch 95, Batch 300: Loss 0.946 Accuracy 0.674\n",
      "Epoch 95, Batch 400: Loss 0.961 Accuracy 0.663\n",
      "Epoch 95, Validation Accuracy: 0.618\n",
      "Epoch 96, Batch 100: Loss 0.925 Accuracy 0.683\n",
      "Epoch 96, Batch 200: Loss 0.951 Accuracy 0.666\n",
      "Epoch 96, Batch 300: Loss 0.856 Accuracy 0.713\n",
      "Epoch 96, Batch 400: Loss 0.958 Accuracy 0.664\n",
      "Epoch 96, Validation Accuracy: 0.588\n",
      "Epoch 97, Batch 100: Loss 0.927 Accuracy 0.689\n",
      "Epoch 97, Batch 200: Loss 0.929 Accuracy 0.687\n",
      "Epoch 97, Batch 300: Loss 0.948 Accuracy 0.671\n",
      "Epoch 97, Batch 400: Loss 0.950 Accuracy 0.671\n",
      "Epoch 97, Validation Accuracy: 0.603\n",
      "Epoch 98, Batch 100: Loss 0.951 Accuracy 0.667\n",
      "Epoch 98, Batch 200: Loss 0.924 Accuracy 0.680\n",
      "Epoch 98, Batch 300: Loss 0.955 Accuracy 0.670\n",
      "Epoch 98, Batch 400: Loss 0.953 Accuracy 0.685\n",
      "Epoch 98, Validation Accuracy: 0.617\n",
      "Epoch 99, Batch 100: Loss 0.912 Accuracy 0.686\n",
      "Epoch 99, Batch 200: Loss 0.939 Accuracy 0.680\n",
      "Epoch 99, Batch 300: Loss 0.941 Accuracy 0.680\n",
      "Epoch 99, Batch 400: Loss 0.932 Accuracy 0.674\n",
      "Epoch 99, Validation Accuracy: 0.617\n",
      "Epoch 100, Batch 100: Loss 0.939 Accuracy 0.682\n",
      "Epoch 100, Batch 200: Loss 0.901 Accuracy 0.693\n",
      "Epoch 100, Batch 300: Loss 0.935 Accuracy 0.683\n",
      "Epoch 100, Batch 400: Loss 0.986 Accuracy 0.659\n",
      "Epoch 100, Validation Accuracy: 0.567\n"
     ]
    }
   ],
   "source": [
    "#Trianing + Validation\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}: Loss {running_loss/100:.3f} Accuracy {correct / total:.3f}\")\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            \n",
    "    #validation \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            if device.type == 'cuda':\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.type(torch.LongTensor).cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56c923eb-b604-40a8-890a-20c36f27d62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 0.624\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\" Test Accuracy: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a8c99-f9aa-4098-aef7-f564531bcdb0",
   "metadata": {},
   "source": [
    "# CNN+Learning Rate Decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35ba7eb-ae59-4d1b-bdac-9ef39a3e4ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b9cef1b-af2c-4d15-a250-980f4ce733e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_lr(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_lr, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=256*14*14, out_features=512)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8a1194a-e33b-4706-a6e0-aa3f1c30cce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = CNN_lr().to(device)\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr,\n",
    "                    weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eee4905-3aa3-4984-8d03-f0a90b6220c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100: Loss 1.859 Accuracy 0.336\n",
      "Epoch 1, Batch 200: Loss 1.419 Accuracy 0.497\n",
      "Epoch 1, Batch 300: Loss 1.220 Accuracy 0.591\n",
      "Epoch 1, Batch 400: Loss 1.133 Accuracy 0.623\n",
      "Epoch 1, Validation Accuracy: 0.642\n",
      "Epoch 2, Batch 100: Loss 1.005 Accuracy 0.660\n",
      "Epoch 2, Batch 200: Loss 0.956 Accuracy 0.672\n",
      "Epoch 2, Batch 300: Loss 0.947 Accuracy 0.680\n",
      "Epoch 2, Batch 400: Loss 0.930 Accuracy 0.682\n",
      "Epoch 2, Validation Accuracy: 0.688\n",
      "Epoch 3, Batch 100: Loss 0.772 Accuracy 0.748\n",
      "Epoch 3, Batch 200: Loss 0.820 Accuracy 0.727\n",
      "Epoch 3, Batch 300: Loss 0.841 Accuracy 0.716\n",
      "Epoch 3, Batch 400: Loss 0.869 Accuracy 0.709\n",
      "Epoch 3, Validation Accuracy: 0.739\n",
      "Epoch 4, Batch 100: Loss 0.686 Accuracy 0.782\n",
      "Epoch 4, Batch 200: Loss 0.723 Accuracy 0.753\n",
      "Epoch 4, Batch 300: Loss 0.745 Accuracy 0.743\n",
      "Epoch 4, Batch 400: Loss 0.746 Accuracy 0.757\n",
      "Epoch 4, Validation Accuracy: 0.743\n",
      "Epoch 5, Batch 100: Loss 0.584 Accuracy 0.805\n",
      "Epoch 5, Batch 200: Loss 0.650 Accuracy 0.778\n",
      "Epoch 5, Batch 300: Loss 0.653 Accuracy 0.778\n",
      "Epoch 5, Batch 400: Loss 0.634 Accuracy 0.787\n",
      "Epoch 5, Validation Accuracy: 0.756\n",
      "Epoch 6, Batch 100: Loss 0.558 Accuracy 0.811\n",
      "Epoch 6, Batch 200: Loss 0.564 Accuracy 0.809\n",
      "Epoch 6, Batch 300: Loss 0.574 Accuracy 0.812\n",
      "Epoch 6, Batch 400: Loss 0.578 Accuracy 0.805\n",
      "Epoch 6, Validation Accuracy: 0.750\n",
      "Epoch 7, Batch 100: Loss 0.449 Accuracy 0.849\n",
      "Epoch 7, Batch 200: Loss 0.470 Accuracy 0.843\n",
      "Epoch 7, Batch 300: Loss 0.539 Accuracy 0.817\n",
      "Epoch 7, Batch 400: Loss 0.522 Accuracy 0.828\n",
      "Epoch 7, Validation Accuracy: 0.779\n",
      "Epoch 8, Batch 100: Loss 0.401 Accuracy 0.871\n",
      "Epoch 8, Batch 200: Loss 0.413 Accuracy 0.864\n",
      "Epoch 8, Batch 300: Loss 0.440 Accuracy 0.848\n",
      "Epoch 8, Batch 400: Loss 0.484 Accuracy 0.835\n",
      "Epoch 8, Validation Accuracy: 0.781\n",
      "Epoch 9, Batch 100: Loss 0.314 Accuracy 0.902\n",
      "Epoch 9, Batch 200: Loss 0.384 Accuracy 0.879\n",
      "Epoch 9, Batch 300: Loss 0.389 Accuracy 0.869\n",
      "Epoch 9, Batch 400: Loss 0.437 Accuracy 0.846\n",
      "Epoch 9, Validation Accuracy: 0.783\n",
      "Epoch 10, Batch 100: Loss 0.334 Accuracy 0.890\n",
      "Epoch 10, Batch 200: Loss 0.299 Accuracy 0.905\n",
      "Epoch 10, Batch 300: Loss 0.379 Accuracy 0.879\n",
      "Epoch 10, Batch 400: Loss 0.373 Accuracy 0.871\n",
      "Epoch 10, Validation Accuracy: 0.796\n",
      "Epoch 11, Batch 100: Loss 0.294 Accuracy 0.903\n",
      "Epoch 11, Batch 200: Loss 0.291 Accuracy 0.909\n",
      "Epoch 11, Batch 300: Loss 0.325 Accuracy 0.901\n",
      "Epoch 11, Batch 400: Loss 0.352 Accuracy 0.878\n",
      "Epoch 11, Validation Accuracy: 0.797\n",
      "Epoch 12, Batch 100: Loss 0.234 Accuracy 0.927\n",
      "Epoch 12, Batch 200: Loss 0.256 Accuracy 0.922\n",
      "Epoch 12, Batch 300: Loss 0.308 Accuracy 0.892\n",
      "Epoch 12, Batch 400: Loss 0.341 Accuracy 0.888\n",
      "Epoch 12, Validation Accuracy: 0.791\n",
      "Epoch 13, Batch 100: Loss 0.247 Accuracy 0.924\n",
      "Epoch 13, Batch 200: Loss 0.281 Accuracy 0.909\n",
      "Epoch 13, Batch 300: Loss 0.282 Accuracy 0.907\n",
      "Epoch 13, Batch 400: Loss 0.310 Accuracy 0.894\n",
      "Epoch 13, Validation Accuracy: 0.801\n",
      "Epoch 14, Batch 100: Loss 0.217 Accuracy 0.933\n",
      "Epoch 14, Batch 200: Loss 0.259 Accuracy 0.918\n",
      "Epoch 14, Batch 300: Loss 0.254 Accuracy 0.919\n",
      "Epoch 14, Batch 400: Loss 0.279 Accuracy 0.904\n",
      "Epoch 14, Validation Accuracy: 0.831\n",
      "Epoch 15, Batch 100: Loss 0.197 Accuracy 0.940\n",
      "Epoch 15, Batch 200: Loss 0.212 Accuracy 0.933\n",
      "Epoch 15, Batch 300: Loss 0.243 Accuracy 0.923\n",
      "Epoch 15, Batch 400: Loss 0.285 Accuracy 0.906\n",
      "Epoch 15, Validation Accuracy: 0.801\n",
      "Epoch 16, Batch 100: Loss 0.233 Accuracy 0.921\n",
      "Epoch 16, Batch 200: Loss 0.216 Accuracy 0.933\n",
      "Epoch 16, Batch 300: Loss 0.238 Accuracy 0.926\n",
      "Epoch 16, Batch 400: Loss 0.264 Accuracy 0.910\n",
      "Epoch 16, Validation Accuracy: 0.798\n",
      "Epoch 17, Batch 100: Loss 0.175 Accuracy 0.943\n",
      "Epoch 17, Batch 200: Loss 0.208 Accuracy 0.930\n",
      "Epoch 17, Batch 300: Loss 0.258 Accuracy 0.916\n",
      "Epoch 17, Batch 400: Loss 0.259 Accuracy 0.913\n",
      "Epoch 17, Validation Accuracy: 0.808\n",
      "Epoch 18, Batch 100: Loss 0.193 Accuracy 0.937\n",
      "Epoch 18, Batch 200: Loss 0.219 Accuracy 0.928\n",
      "Epoch 18, Batch 300: Loss 0.209 Accuracy 0.928\n",
      "Epoch 18, Batch 400: Loss 0.229 Accuracy 0.925\n",
      "Epoch 18, Validation Accuracy: 0.806\n",
      "Epoch 19, Batch 100: Loss 0.206 Accuracy 0.938\n",
      "Epoch 19, Batch 200: Loss 0.186 Accuracy 0.942\n",
      "Epoch 19, Batch 300: Loss 0.212 Accuracy 0.934\n",
      "Epoch 19, Batch 400: Loss 0.254 Accuracy 0.912\n",
      "Epoch 19, Validation Accuracy: 0.815\n",
      "Epoch 20, Batch 100: Loss 0.184 Accuracy 0.943\n",
      "Epoch 20, Batch 200: Loss 0.193 Accuracy 0.929\n",
      "Epoch 20, Batch 300: Loss 0.210 Accuracy 0.929\n",
      "Epoch 20, Batch 400: Loss 0.243 Accuracy 0.918\n",
      "Epoch 20, Validation Accuracy: 0.817\n",
      "Epoch 21, Batch 100: Loss 0.145 Accuracy 0.957\n",
      "Epoch 21, Batch 200: Loss 0.119 Accuracy 0.966\n",
      "Epoch 21, Batch 300: Loss 0.117 Accuracy 0.965\n",
      "Epoch 21, Batch 400: Loss 0.122 Accuracy 0.968\n",
      "Epoch 21, Validation Accuracy: 0.855\n",
      "Epoch 22, Batch 100: Loss 0.094 Accuracy 0.975\n",
      "Epoch 22, Batch 200: Loss 0.096 Accuracy 0.975\n",
      "Epoch 22, Batch 300: Loss 0.071 Accuracy 0.985\n",
      "Epoch 22, Batch 400: Loss 0.078 Accuracy 0.980\n",
      "Epoch 22, Validation Accuracy: 0.848\n",
      "Epoch 23, Batch 100: Loss 0.073 Accuracy 0.984\n",
      "Epoch 23, Batch 200: Loss 0.070 Accuracy 0.987\n",
      "Epoch 23, Batch 300: Loss 0.072 Accuracy 0.982\n",
      "Epoch 23, Batch 400: Loss 0.062 Accuracy 0.987\n",
      "Epoch 23, Validation Accuracy: 0.854\n",
      "Epoch 24, Batch 100: Loss 0.049 Accuracy 0.989\n",
      "Epoch 24, Batch 200: Loss 0.058 Accuracy 0.988\n",
      "Epoch 24, Batch 300: Loss 0.061 Accuracy 0.987\n",
      "Epoch 24, Batch 400: Loss 0.055 Accuracy 0.988\n",
      "Epoch 24, Validation Accuracy: 0.865\n",
      "Epoch 25, Batch 100: Loss 0.049 Accuracy 0.989\n",
      "Epoch 25, Batch 200: Loss 0.045 Accuracy 0.989\n",
      "Epoch 25, Batch 300: Loss 0.054 Accuracy 0.988\n",
      "Epoch 25, Batch 400: Loss 0.047 Accuracy 0.991\n",
      "Epoch 25, Validation Accuracy: 0.864\n",
      "Epoch 26, Batch 100: Loss 0.041 Accuracy 0.993\n",
      "Epoch 26, Batch 200: Loss 0.043 Accuracy 0.990\n",
      "Epoch 26, Batch 300: Loss 0.046 Accuracy 0.990\n",
      "Epoch 26, Batch 400: Loss 0.043 Accuracy 0.992\n",
      "Epoch 26, Validation Accuracy: 0.864\n",
      "Epoch 27, Batch 100: Loss 0.037 Accuracy 0.994\n",
      "Epoch 27, Batch 200: Loss 0.036 Accuracy 0.992\n",
      "Epoch 27, Batch 300: Loss 0.036 Accuracy 0.993\n",
      "Epoch 27, Batch 400: Loss 0.041 Accuracy 0.992\n",
      "Epoch 27, Validation Accuracy: 0.863\n",
      "Epoch 28, Batch 100: Loss 0.033 Accuracy 0.993\n",
      "Epoch 28, Batch 200: Loss 0.037 Accuracy 0.993\n",
      "Epoch 28, Batch 300: Loss 0.030 Accuracy 0.995\n",
      "Epoch 28, Batch 400: Loss 0.039 Accuracy 0.991\n",
      "Epoch 28, Validation Accuracy: 0.863\n",
      "Epoch 29, Batch 100: Loss 0.030 Accuracy 0.994\n",
      "Epoch 29, Batch 200: Loss 0.031 Accuracy 0.995\n",
      "Epoch 29, Batch 300: Loss 0.030 Accuracy 0.994\n",
      "Epoch 29, Batch 400: Loss 0.029 Accuracy 0.994\n",
      "Epoch 29, Validation Accuracy: 0.867\n",
      "Epoch 30, Batch 100: Loss 0.023 Accuracy 0.997\n",
      "Epoch 30, Batch 200: Loss 0.030 Accuracy 0.994\n",
      "Epoch 30, Batch 300: Loss 0.032 Accuracy 0.993\n",
      "Epoch 30, Batch 400: Loss 0.032 Accuracy 0.995\n",
      "Epoch 30, Validation Accuracy: 0.855\n",
      "Epoch 31, Batch 100: Loss 0.024 Accuracy 0.997\n",
      "Epoch 31, Batch 200: Loss 0.021 Accuracy 0.997\n",
      "Epoch 31, Batch 300: Loss 0.031 Accuracy 0.993\n",
      "Epoch 31, Batch 400: Loss 0.032 Accuracy 0.993\n",
      "Epoch 31, Validation Accuracy: 0.852\n",
      "Epoch 32, Batch 100: Loss 0.028 Accuracy 0.993\n",
      "Epoch 32, Batch 200: Loss 0.031 Accuracy 0.994\n",
      "Epoch 32, Batch 300: Loss 0.029 Accuracy 0.994\n",
      "Epoch 32, Batch 400: Loss 0.031 Accuracy 0.995\n",
      "Epoch 32, Validation Accuracy: 0.859\n",
      "Epoch 33, Batch 100: Loss 0.026 Accuracy 0.996\n",
      "Epoch 33, Batch 200: Loss 0.026 Accuracy 0.995\n",
      "Epoch 33, Batch 300: Loss 0.023 Accuracy 0.996\n",
      "Epoch 33, Batch 400: Loss 0.024 Accuracy 0.996\n",
      "Epoch 33, Validation Accuracy: 0.857\n",
      "Epoch 34, Batch 100: Loss 0.020 Accuracy 0.998\n",
      "Epoch 34, Batch 200: Loss 0.025 Accuracy 0.995\n",
      "Epoch 34, Batch 300: Loss 0.028 Accuracy 0.993\n",
      "Epoch 34, Batch 400: Loss 0.029 Accuracy 0.995\n",
      "Epoch 34, Validation Accuracy: 0.851\n",
      "Epoch 35, Batch 100: Loss 0.021 Accuracy 0.997\n",
      "Epoch 35, Batch 200: Loss 0.024 Accuracy 0.996\n",
      "Epoch 35, Batch 300: Loss 0.024 Accuracy 0.997\n",
      "Epoch 35, Batch 400: Loss 0.029 Accuracy 0.995\n",
      "Epoch 35, Validation Accuracy: 0.868\n",
      "Epoch 36, Batch 100: Loss 0.022 Accuracy 0.997\n",
      "Epoch 36, Batch 200: Loss 0.020 Accuracy 0.997\n",
      "Epoch 36, Batch 300: Loss 0.021 Accuracy 0.997\n",
      "Epoch 36, Batch 400: Loss 0.024 Accuracy 0.996\n",
      "Epoch 36, Validation Accuracy: 0.850\n",
      "Epoch 37, Batch 100: Loss 0.017 Accuracy 0.998\n",
      "Epoch 37, Batch 200: Loss 0.018 Accuracy 0.997\n",
      "Epoch 37, Batch 300: Loss 0.021 Accuracy 0.995\n",
      "Epoch 37, Batch 400: Loss 0.020 Accuracy 0.997\n",
      "Epoch 37, Validation Accuracy: 0.863\n",
      "Epoch 38, Batch 100: Loss 0.015 Accuracy 0.999\n",
      "Epoch 38, Batch 200: Loss 0.023 Accuracy 0.995\n",
      "Epoch 38, Batch 300: Loss 0.021 Accuracy 0.997\n",
      "Epoch 38, Batch 400: Loss 0.025 Accuracy 0.995\n",
      "Epoch 38, Validation Accuracy: 0.860\n",
      "Epoch 39, Batch 100: Loss 0.021 Accuracy 0.996\n",
      "Epoch 39, Batch 200: Loss 0.018 Accuracy 0.997\n",
      "Epoch 39, Batch 300: Loss 0.018 Accuracy 0.998\n",
      "Epoch 39, Batch 400: Loss 0.022 Accuracy 0.995\n",
      "Epoch 39, Validation Accuracy: 0.850\n",
      "Epoch 40, Batch 100: Loss 0.020 Accuracy 0.997\n",
      "Epoch 40, Batch 200: Loss 0.020 Accuracy 0.996\n",
      "Epoch 40, Batch 300: Loss 0.020 Accuracy 0.997\n",
      "Epoch 40, Batch 400: Loss 0.025 Accuracy 0.994\n",
      "Epoch 40, Validation Accuracy: 0.863\n",
      "Epoch 41, Batch 100: Loss 0.014 Accuracy 0.999\n",
      "Epoch 41, Batch 200: Loss 0.022 Accuracy 0.996\n",
      "Epoch 41, Batch 300: Loss 0.018 Accuracy 0.998\n",
      "Epoch 41, Batch 400: Loss 0.016 Accuracy 0.998\n",
      "Epoch 41, Validation Accuracy: 0.868\n",
      "Epoch 42, Batch 100: Loss 0.018 Accuracy 0.998\n",
      "Epoch 42, Batch 200: Loss 0.017 Accuracy 0.998\n",
      "Epoch 42, Batch 300: Loss 0.017 Accuracy 0.998\n",
      "Epoch 42, Batch 400: Loss 0.014 Accuracy 0.998\n",
      "Epoch 42, Validation Accuracy: 0.861\n",
      "Epoch 43, Batch 100: Loss 0.014 Accuracy 0.999\n",
      "Epoch 43, Batch 200: Loss 0.015 Accuracy 0.998\n",
      "Epoch 43, Batch 300: Loss 0.017 Accuracy 0.998\n",
      "Epoch 43, Batch 400: Loss 0.013 Accuracy 0.999\n",
      "Epoch 43, Validation Accuracy: 0.866\n",
      "Epoch 44, Batch 100: Loss 0.012 Accuracy 0.998\n",
      "Epoch 44, Batch 200: Loss 0.012 Accuracy 0.999\n",
      "Epoch 44, Batch 300: Loss 0.016 Accuracy 0.996\n",
      "Epoch 44, Batch 400: Loss 0.016 Accuracy 0.997\n",
      "Epoch 44, Validation Accuracy: 0.865\n",
      "Epoch 45, Batch 100: Loss 0.014 Accuracy 0.998\n",
      "Epoch 45, Batch 200: Loss 0.011 Accuracy 0.999\n",
      "Epoch 45, Batch 300: Loss 0.014 Accuracy 0.998\n",
      "Epoch 45, Batch 400: Loss 0.017 Accuracy 0.998\n",
      "Epoch 45, Validation Accuracy: 0.857\n",
      "Epoch 46, Batch 100: Loss 0.011 Accuracy 0.999\n",
      "Epoch 46, Batch 200: Loss 0.015 Accuracy 0.997\n",
      "Epoch 46, Batch 300: Loss 0.014 Accuracy 0.998\n",
      "Epoch 46, Batch 400: Loss 0.013 Accuracy 0.998\n",
      "Epoch 46, Validation Accuracy: 0.865\n",
      "Epoch 47, Batch 100: Loss 0.015 Accuracy 0.998\n",
      "Epoch 47, Batch 200: Loss 0.013 Accuracy 0.998\n",
      "Epoch 47, Batch 300: Loss 0.012 Accuracy 0.999\n",
      "Epoch 47, Batch 400: Loss 0.013 Accuracy 0.997\n",
      "Epoch 47, Validation Accuracy: 0.867\n",
      "Epoch 48, Batch 100: Loss 0.012 Accuracy 0.998\n",
      "Epoch 48, Batch 200: Loss 0.011 Accuracy 0.999\n",
      "Epoch 48, Batch 300: Loss 0.013 Accuracy 0.998\n",
      "Epoch 48, Batch 400: Loss 0.010 Accuracy 0.999\n",
      "Epoch 48, Validation Accuracy: 0.863\n",
      "Epoch 49, Batch 100: Loss 0.010 Accuracy 1.000\n",
      "Epoch 49, Batch 200: Loss 0.014 Accuracy 0.998\n",
      "Epoch 49, Batch 300: Loss 0.010 Accuracy 0.998\n",
      "Epoch 49, Batch 400: Loss 0.010 Accuracy 0.998\n",
      "Epoch 49, Validation Accuracy: 0.864\n",
      "Epoch 50, Batch 100: Loss 0.012 Accuracy 0.998\n",
      "Epoch 50, Batch 200: Loss 0.013 Accuracy 0.998\n",
      "Epoch 50, Batch 300: Loss 0.010 Accuracy 0.998\n",
      "Epoch 50, Batch 400: Loss 0.009 Accuracy 0.998\n",
      "Epoch 50, Validation Accuracy: 0.867\n"
     ]
    }
   ],
   "source": [
    "#Trianing + Validation\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}: Loss {running_loss/100:.3f} Accuracy {correct / total:.3f}\")\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            \n",
    "    #validation \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            if device.type == 'cuda':\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.type(torch.LongTensor).cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {val_acc:.3f}\")\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95610265-e9ae-4b82-8576-2567a9fbff2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 0.865\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\" Test Accuracy: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72c817-1e0c-449b-bb52-f3ed2cf25d6c",
   "metadata": {},
   "source": [
    "# CNN+Learning Rate Decay+Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27d8baf1-095e-4d8c-836f-2085f56aebc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.res1 = ResBlock(32, 32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.res2 = ResBlock(64, 64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.res3 = ResBlock(128, 128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.res4 = ResBlock(256, 256)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(in_features=256*14*14, out_features=512)\n",
    "        self.bn5 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.res4(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7389624e-1b35-483b-b5e5-ab16501f381f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = ResCNN().to(device)\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr,\n",
    "                    weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "018c08f9-53df-4b37-9988-45a75988fbc8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100: Loss 1.833 Accuracy 0.339\n",
      "Epoch 1, Batch 200: Loss 1.545 Accuracy 0.457\n",
      "Epoch 1, Batch 300: Loss 1.365 Accuracy 0.525\n",
      "Epoch 1, Batch 400: Loss 1.255 Accuracy 0.569\n",
      "Epoch 1, Validation Accuracy: 0.609\n",
      "Epoch 2, Batch 100: Loss 1.048 Accuracy 0.642\n",
      "Epoch 2, Batch 200: Loss 1.044 Accuracy 0.644\n",
      "Epoch 2, Batch 300: Loss 1.023 Accuracy 0.652\n",
      "Epoch 2, Batch 400: Loss 0.957 Accuracy 0.677\n",
      "Epoch 2, Validation Accuracy: 0.655\n",
      "Epoch 3, Batch 100: Loss 0.866 Accuracy 0.703\n",
      "Epoch 3, Batch 200: Loss 0.861 Accuracy 0.712\n",
      "Epoch 3, Batch 300: Loss 0.855 Accuracy 0.710\n",
      "Epoch 3, Batch 400: Loss 0.796 Accuracy 0.730\n",
      "Epoch 3, Validation Accuracy: 0.705\n",
      "Epoch 4, Batch 100: Loss 0.677 Accuracy 0.767\n",
      "Epoch 4, Batch 200: Loss 0.716 Accuracy 0.765\n",
      "Epoch 4, Batch 300: Loss 0.762 Accuracy 0.745\n",
      "Epoch 4, Batch 400: Loss 0.745 Accuracy 0.742\n",
      "Epoch 4, Validation Accuracy: 0.751\n",
      "Epoch 5, Batch 100: Loss 0.581 Accuracy 0.808\n",
      "Epoch 5, Batch 200: Loss 0.616 Accuracy 0.793\n",
      "Epoch 5, Batch 300: Loss 0.664 Accuracy 0.779\n",
      "Epoch 5, Batch 400: Loss 0.648 Accuracy 0.785\n",
      "Epoch 5, Validation Accuracy: 0.778\n",
      "Epoch 6, Batch 100: Loss 0.499 Accuracy 0.831\n",
      "Epoch 6, Batch 200: Loss 0.528 Accuracy 0.822\n",
      "Epoch 6, Batch 300: Loss 0.531 Accuracy 0.814\n",
      "Epoch 6, Batch 400: Loss 0.611 Accuracy 0.791\n",
      "Epoch 6, Validation Accuracy: 0.795\n",
      "Epoch 7, Batch 100: Loss 0.419 Accuracy 0.863\n",
      "Epoch 7, Batch 200: Loss 0.463 Accuracy 0.838\n",
      "Epoch 7, Batch 300: Loss 0.488 Accuracy 0.833\n",
      "Epoch 7, Batch 400: Loss 0.479 Accuracy 0.838\n",
      "Epoch 7, Validation Accuracy: 0.796\n",
      "Epoch 8, Batch 100: Loss 0.358 Accuracy 0.881\n",
      "Epoch 8, Batch 200: Loss 0.401 Accuracy 0.860\n",
      "Epoch 8, Batch 300: Loss 0.456 Accuracy 0.839\n",
      "Epoch 8, Batch 400: Loss 0.450 Accuracy 0.844\n",
      "Epoch 8, Validation Accuracy: 0.810\n",
      "Epoch 9, Batch 100: Loss 0.292 Accuracy 0.903\n",
      "Epoch 9, Batch 200: Loss 0.357 Accuracy 0.879\n",
      "Epoch 9, Batch 300: Loss 0.364 Accuracy 0.876\n",
      "Epoch 9, Batch 400: Loss 0.397 Accuracy 0.865\n",
      "Epoch 9, Validation Accuracy: 0.797\n",
      "Epoch 10, Batch 100: Loss 0.245 Accuracy 0.922\n",
      "Epoch 10, Batch 200: Loss 0.278 Accuracy 0.907\n",
      "Epoch 10, Batch 300: Loss 0.303 Accuracy 0.894\n",
      "Epoch 10, Batch 400: Loss 0.372 Accuracy 0.870\n",
      "Epoch 10, Validation Accuracy: 0.796\n",
      "Epoch 11, Batch 100: Loss 0.274 Accuracy 0.914\n",
      "Epoch 11, Batch 200: Loss 0.237 Accuracy 0.922\n",
      "Epoch 11, Batch 300: Loss 0.305 Accuracy 0.901\n",
      "Epoch 11, Batch 400: Loss 0.327 Accuracy 0.891\n",
      "Epoch 11, Validation Accuracy: 0.814\n",
      "Epoch 12, Batch 100: Loss 0.254 Accuracy 0.917\n",
      "Epoch 12, Batch 200: Loss 0.238 Accuracy 0.922\n",
      "Epoch 12, Batch 300: Loss 0.256 Accuracy 0.919\n",
      "Epoch 12, Batch 400: Loss 0.272 Accuracy 0.905\n",
      "Epoch 12, Validation Accuracy: 0.819\n",
      "Epoch 13, Batch 100: Loss 0.215 Accuracy 0.933\n",
      "Epoch 13, Batch 200: Loss 0.218 Accuracy 0.928\n",
      "Epoch 13, Batch 300: Loss 0.245 Accuracy 0.920\n",
      "Epoch 13, Batch 400: Loss 0.290 Accuracy 0.904\n",
      "Epoch 13, Validation Accuracy: 0.815\n",
      "Epoch 14, Batch 100: Loss 0.196 Accuracy 0.939\n",
      "Epoch 14, Batch 200: Loss 0.198 Accuracy 0.936\n",
      "Epoch 14, Batch 300: Loss 0.236 Accuracy 0.922\n",
      "Epoch 14, Batch 400: Loss 0.255 Accuracy 0.913\n",
      "Epoch 14, Validation Accuracy: 0.819\n",
      "Epoch 15, Batch 100: Loss 0.171 Accuracy 0.947\n",
      "Epoch 15, Batch 200: Loss 0.195 Accuracy 0.935\n",
      "Epoch 15, Batch 300: Loss 0.244 Accuracy 0.918\n",
      "Epoch 15, Batch 400: Loss 0.256 Accuracy 0.912\n",
      "Epoch 15, Validation Accuracy: 0.825\n",
      "Epoch 16, Batch 100: Loss 0.170 Accuracy 0.947\n",
      "Epoch 16, Batch 200: Loss 0.164 Accuracy 0.944\n",
      "Epoch 16, Batch 300: Loss 0.179 Accuracy 0.942\n",
      "Epoch 16, Batch 400: Loss 0.229 Accuracy 0.924\n",
      "Epoch 16, Validation Accuracy: 0.832\n",
      "Epoch 17, Batch 100: Loss 0.154 Accuracy 0.951\n",
      "Epoch 17, Batch 200: Loss 0.172 Accuracy 0.942\n",
      "Epoch 17, Batch 300: Loss 0.196 Accuracy 0.930\n",
      "Epoch 17, Batch 400: Loss 0.216 Accuracy 0.932\n",
      "Epoch 17, Validation Accuracy: 0.822\n",
      "Epoch 18, Batch 100: Loss 0.151 Accuracy 0.953\n",
      "Epoch 18, Batch 200: Loss 0.148 Accuracy 0.954\n",
      "Epoch 18, Batch 300: Loss 0.196 Accuracy 0.933\n",
      "Epoch 18, Batch 400: Loss 0.215 Accuracy 0.927\n",
      "Epoch 18, Validation Accuracy: 0.835\n",
      "Epoch 19, Batch 100: Loss 0.132 Accuracy 0.960\n",
      "Epoch 19, Batch 200: Loss 0.150 Accuracy 0.950\n",
      "Epoch 19, Batch 300: Loss 0.182 Accuracy 0.941\n",
      "Epoch 19, Batch 400: Loss 0.230 Accuracy 0.924\n",
      "Epoch 19, Validation Accuracy: 0.838\n",
      "Epoch 20, Batch 100: Loss 0.135 Accuracy 0.953\n",
      "Epoch 20, Batch 200: Loss 0.178 Accuracy 0.939\n",
      "Epoch 20, Batch 300: Loss 0.187 Accuracy 0.938\n",
      "Epoch 20, Batch 400: Loss 0.201 Accuracy 0.930\n",
      "Epoch 20, Validation Accuracy: 0.816\n",
      "Epoch 21, Batch 100: Loss 0.109 Accuracy 0.969\n",
      "Epoch 21, Batch 200: Loss 0.081 Accuracy 0.978\n",
      "Epoch 21, Batch 300: Loss 0.076 Accuracy 0.978\n",
      "Epoch 21, Batch 400: Loss 0.079 Accuracy 0.980\n",
      "Epoch 21, Validation Accuracy: 0.861\n",
      "Epoch 22, Batch 100: Loss 0.068 Accuracy 0.981\n",
      "Epoch 22, Batch 200: Loss 0.053 Accuracy 0.987\n",
      "Epoch 22, Batch 300: Loss 0.050 Accuracy 0.989\n",
      "Epoch 22, Batch 400: Loss 0.047 Accuracy 0.989\n",
      "Epoch 22, Validation Accuracy: 0.879\n",
      "Epoch 23, Batch 100: Loss 0.045 Accuracy 0.991\n",
      "Epoch 23, Batch 200: Loss 0.040 Accuracy 0.990\n",
      "Epoch 23, Batch 300: Loss 0.039 Accuracy 0.993\n",
      "Epoch 23, Batch 400: Loss 0.036 Accuracy 0.993\n",
      "Epoch 23, Validation Accuracy: 0.883\n",
      "Epoch 24, Batch 100: Loss 0.031 Accuracy 0.994\n",
      "Epoch 24, Batch 200: Loss 0.029 Accuracy 0.995\n",
      "Epoch 24, Batch 300: Loss 0.031 Accuracy 0.994\n",
      "Epoch 24, Batch 400: Loss 0.031 Accuracy 0.994\n",
      "Epoch 24, Validation Accuracy: 0.881\n",
      "Epoch 25, Batch 100: Loss 0.029 Accuracy 0.996\n",
      "Epoch 25, Batch 200: Loss 0.026 Accuracy 0.995\n",
      "Epoch 25, Batch 300: Loss 0.025 Accuracy 0.996\n",
      "Epoch 25, Batch 400: Loss 0.024 Accuracy 0.997\n",
      "Epoch 25, Validation Accuracy: 0.888\n",
      "Epoch 26, Batch 100: Loss 0.020 Accuracy 0.996\n",
      "Epoch 26, Batch 200: Loss 0.024 Accuracy 0.996\n",
      "Epoch 26, Batch 300: Loss 0.025 Accuracy 0.995\n",
      "Epoch 26, Batch 400: Loss 0.021 Accuracy 0.997\n",
      "Epoch 26, Validation Accuracy: 0.888\n",
      "Epoch 27, Batch 100: Loss 0.020 Accuracy 0.997\n",
      "Epoch 27, Batch 200: Loss 0.020 Accuracy 0.997\n",
      "Epoch 27, Batch 300: Loss 0.018 Accuracy 0.998\n",
      "Epoch 27, Batch 400: Loss 0.022 Accuracy 0.995\n",
      "Epoch 27, Validation Accuracy: 0.884\n",
      "Epoch 28, Batch 100: Loss 0.020 Accuracy 0.996\n",
      "Epoch 28, Batch 200: Loss 0.014 Accuracy 0.999\n",
      "Epoch 28, Batch 300: Loss 0.015 Accuracy 0.998\n",
      "Epoch 28, Batch 400: Loss 0.020 Accuracy 0.996\n",
      "Epoch 28, Validation Accuracy: 0.889\n",
      "Epoch 29, Batch 100: Loss 0.020 Accuracy 0.997\n",
      "Epoch 29, Batch 200: Loss 0.019 Accuracy 0.997\n",
      "Epoch 29, Batch 300: Loss 0.015 Accuracy 0.998\n",
      "Epoch 29, Batch 400: Loss 0.015 Accuracy 0.998\n",
      "Epoch 29, Validation Accuracy: 0.888\n",
      "Epoch 30, Batch 100: Loss 0.014 Accuracy 0.998\n",
      "Epoch 30, Batch 200: Loss 0.012 Accuracy 0.999\n",
      "Epoch 30, Batch 300: Loss 0.014 Accuracy 0.998\n",
      "Epoch 30, Batch 400: Loss 0.018 Accuracy 0.996\n",
      "Epoch 30, Validation Accuracy: 0.884\n",
      "Epoch 31, Batch 100: Loss 0.013 Accuracy 0.998\n",
      "Epoch 31, Batch 200: Loss 0.016 Accuracy 0.998\n",
      "Epoch 31, Batch 300: Loss 0.014 Accuracy 0.998\n",
      "Epoch 31, Batch 400: Loss 0.014 Accuracy 0.998\n",
      "Epoch 31, Validation Accuracy: 0.894\n",
      "Epoch 32, Batch 100: Loss 0.013 Accuracy 0.998\n",
      "Epoch 32, Batch 200: Loss 0.013 Accuracy 0.999\n",
      "Epoch 32, Batch 300: Loss 0.014 Accuracy 0.998\n",
      "Epoch 32, Batch 400: Loss 0.021 Accuracy 0.996\n",
      "Epoch 32, Validation Accuracy: 0.880\n",
      "Epoch 33, Batch 100: Loss 0.015 Accuracy 0.998\n",
      "Epoch 33, Batch 200: Loss 0.012 Accuracy 0.999\n",
      "Epoch 33, Batch 300: Loss 0.015 Accuracy 0.998\n",
      "Epoch 33, Batch 400: Loss 0.011 Accuracy 0.999\n",
      "Epoch 33, Validation Accuracy: 0.890\n",
      "Epoch 34, Batch 100: Loss 0.011 Accuracy 0.999\n",
      "Epoch 34, Batch 200: Loss 0.020 Accuracy 0.996\n",
      "Epoch 34, Batch 300: Loss 0.014 Accuracy 0.998\n",
      "Epoch 34, Batch 400: Loss 0.012 Accuracy 0.999\n",
      "Epoch 34, Validation Accuracy: 0.888\n",
      "Epoch 35, Batch 100: Loss 0.013 Accuracy 0.999\n",
      "Epoch 35, Batch 200: Loss 0.011 Accuracy 0.999\n",
      "Epoch 35, Batch 300: Loss 0.014 Accuracy 0.997\n",
      "Epoch 35, Batch 400: Loss 0.023 Accuracy 0.997\n",
      "Epoch 35, Validation Accuracy: 0.882\n",
      "Epoch 36, Batch 100: Loss 0.014 Accuracy 0.998\n",
      "Epoch 36, Batch 200: Loss 0.013 Accuracy 0.999\n",
      "Epoch 36, Batch 300: Loss 0.015 Accuracy 0.999\n",
      "Epoch 36, Batch 400: Loss 0.018 Accuracy 0.997\n",
      "Epoch 36, Validation Accuracy: 0.887\n",
      "Epoch 37, Batch 100: Loss 0.008 Accuracy 1.000\n",
      "Epoch 37, Batch 200: Loss 0.011 Accuracy 0.998\n",
      "Epoch 37, Batch 300: Loss 0.014 Accuracy 0.998\n",
      "Epoch 37, Batch 400: Loss 0.019 Accuracy 0.996\n",
      "Epoch 37, Validation Accuracy: 0.884\n",
      "Epoch 38, Batch 100: Loss 0.011 Accuracy 0.999\n",
      "Epoch 38, Batch 200: Loss 0.015 Accuracy 0.998\n",
      "Epoch 38, Batch 300: Loss 0.012 Accuracy 0.999\n",
      "Epoch 38, Batch 400: Loss 0.017 Accuracy 0.997\n",
      "Epoch 38, Validation Accuracy: 0.877\n",
      "Epoch 39, Batch 100: Loss 0.009 Accuracy 0.999\n",
      "Epoch 39, Batch 200: Loss 0.011 Accuracy 0.999\n",
      "Epoch 39, Batch 300: Loss 0.012 Accuracy 0.999\n",
      "Epoch 39, Batch 400: Loss 0.014 Accuracy 0.998\n",
      "Epoch 39, Validation Accuracy: 0.876\n",
      "Epoch 40, Batch 100: Loss 0.012 Accuracy 0.998\n",
      "Epoch 40, Batch 200: Loss 0.012 Accuracy 0.999\n",
      "Epoch 40, Batch 300: Loss 0.017 Accuracy 0.996\n",
      "Epoch 40, Batch 400: Loss 0.015 Accuracy 0.998\n",
      "Epoch 40, Validation Accuracy: 0.884\n",
      "Epoch 41, Batch 100: Loss 0.009 Accuracy 1.000\n",
      "Epoch 41, Batch 200: Loss 0.008 Accuracy 0.999\n",
      "Epoch 41, Batch 300: Loss 0.012 Accuracy 0.997\n",
      "Epoch 41, Batch 400: Loss 0.010 Accuracy 0.999\n",
      "Epoch 41, Validation Accuracy: 0.886\n",
      "Epoch 42, Batch 100: Loss 0.009 Accuracy 0.999\n",
      "Epoch 42, Batch 200: Loss 0.012 Accuracy 0.998\n",
      "Epoch 42, Batch 300: Loss 0.009 Accuracy 0.999\n",
      "Epoch 42, Batch 400: Loss 0.010 Accuracy 0.998\n",
      "Epoch 42, Validation Accuracy: 0.886\n",
      "Epoch 43, Batch 100: Loss 0.008 Accuracy 1.000\n",
      "Epoch 43, Batch 200: Loss 0.008 Accuracy 0.999\n",
      "Epoch 43, Batch 300: Loss 0.009 Accuracy 0.998\n",
      "Epoch 43, Batch 400: Loss 0.006 Accuracy 1.000\n",
      "Epoch 43, Validation Accuracy: 0.890\n",
      "Epoch 44, Batch 100: Loss 0.009 Accuracy 0.999\n",
      "Epoch 44, Batch 200: Loss 0.007 Accuracy 0.999\n",
      "Epoch 44, Batch 300: Loss 0.009 Accuracy 0.998\n",
      "Epoch 44, Batch 400: Loss 0.010 Accuracy 0.999\n",
      "Epoch 44, Validation Accuracy: 0.892\n",
      "Epoch 45, Batch 100: Loss 0.008 Accuracy 0.998\n",
      "Epoch 45, Batch 200: Loss 0.007 Accuracy 0.999\n",
      "Epoch 45, Batch 300: Loss 0.008 Accuracy 0.999\n",
      "Epoch 45, Batch 400: Loss 0.009 Accuracy 0.999\n",
      "Epoch 45, Validation Accuracy: 0.891\n",
      "Epoch 46, Batch 100: Loss 0.007 Accuracy 0.999\n",
      "Epoch 46, Batch 200: Loss 0.007 Accuracy 0.998\n",
      "Epoch 46, Batch 300: Loss 0.007 Accuracy 0.999\n",
      "Epoch 46, Batch 400: Loss 0.006 Accuracy 0.999\n",
      "Epoch 46, Validation Accuracy: 0.885\n",
      "Epoch 47, Batch 100: Loss 0.006 Accuracy 1.000\n",
      "Epoch 47, Batch 200: Loss 0.008 Accuracy 0.999\n",
      "Epoch 47, Batch 300: Loss 0.009 Accuracy 0.998\n",
      "Epoch 47, Batch 400: Loss 0.008 Accuracy 0.998\n",
      "Epoch 47, Validation Accuracy: 0.887\n",
      "Epoch 48, Batch 100: Loss 0.008 Accuracy 0.999\n",
      "Epoch 48, Batch 200: Loss 0.007 Accuracy 0.999\n",
      "Epoch 48, Batch 300: Loss 0.007 Accuracy 0.998\n",
      "Epoch 48, Batch 400: Loss 0.008 Accuracy 0.999\n",
      "Epoch 48, Validation Accuracy: 0.890\n",
      "Epoch 49, Batch 100: Loss 0.007 Accuracy 0.998\n",
      "Epoch 49, Batch 200: Loss 0.005 Accuracy 1.000\n",
      "Epoch 49, Batch 300: Loss 0.005 Accuracy 1.000\n",
      "Epoch 49, Batch 400: Loss 0.005 Accuracy 0.999\n",
      "Epoch 49, Validation Accuracy: 0.889\n",
      "Epoch 50, Batch 100: Loss 0.008 Accuracy 0.998\n",
      "Epoch 50, Batch 200: Loss 0.007 Accuracy 0.999\n",
      "Epoch 50, Batch 300: Loss 0.006 Accuracy 0.998\n",
      "Epoch 50, Batch 400: Loss 0.005 Accuracy 0.999\n",
      "Epoch 50, Validation Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "#Trianing + Validation\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1}: Loss {running_loss/100:.3f} Accuracy {correct / total:.3f}\")\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            \n",
    "    #validation \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            if device.type == 'cuda':\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.type(torch.LongTensor).cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}, Validation Accuracy: {val_acc:.3f}\")\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7495791-d3a1-4c47-92b0-8592764c0ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 0.886\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        if device.type == 'cuda':\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.type(torch.LongTensor).cuda()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\" Test Accuracy: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd331d-e607-4e84-8a96-b55d3ce6afb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
